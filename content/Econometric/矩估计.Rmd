---
author:
  - 韭菜
title: '矩估计'
categories:
  - R
  - Stata
  - 广义矩估计
  - 矩估计
  - GMM
tags:
  - R
  - Stata
  - 广义矩估计
  - 矩估计
  - GMM
date: 2021-04-21
slug: MM
weight: 001
description: <font face="思源宋体 CN" >广义矩估计 (Generalized Method of Moment, 简称 GMM) 是一种构造估计量的方法，类似于极大似然法 (MLE) 。MLE 通过假设随机变量服从特定的分布，进而将待估参数嵌入似然函数，通过极大化联合概率密度函数得到参数的估计值。GMM 则是以随机变量遵循特定矩的假设，而不是对整个分布的假设，这些假设被称为矩条件。这使得 GMM 比 MLE 更稳健，但会导致估计量的有效性有所降低 (估计出的标准误比较大)</font>
---

<font face="思源宋体 CN" >


　　**几个重要的计量经济学方法的提出时间顺序：**     

- IV，Philip Green Wright[^Philip]，1928；Henri Theil，Olav Reiersøl，1945；    

[^Philip]:![](https://i.loli.net/2021/04/22/RlQO7Wt9BcTXYEJ.jpg)

- GLS，Alexander Aitken[^Alexander]，1935.  

[^Alexander]:![](https://i.loli.net/2021/04/22/1pmr8Vfy4JQWwM7.jpg)

- 2SLS，Henri Theil[^Henri]，1953.   

- 3SLS，Henri Theil[^Henri]，1962，<font color=blue >模型是被用的，而不是被信的。</font> 

[^Henri]:![](https://i.loli.net/2021/04/22/i7b6NDvqWkzOhVx.jpg)

- MM，Karl Pearson1[^Pearson1]，1894. 

[^Pearson1]:![](https://gitee.com/shao818/Figure/raw/master/20210422191915.png)

- GMM，Lars Peter Hansen[^Hansen]，1982. 

[^Hansen]:![Hansen](https://gitee.com/shao818/Figure/raw/master/20210421184457.png)

# 为何要使用 GMM ？

## 过度识别且存在异方差

　　传统的工具变量法2SLS，因为它操作方便，且同时适用于恰好识别与过度识别的情形。然而，<font color=blue >2SLS仅在扰动项同方差的情况下，才是最有效率的</font>。理由很简单，如果每位个体的扰动项方差不相同（比如，大企业的方差一般不同于小企业的方差），则方差小的个体观测值所包含的信息量更大，而2SLS却对所有数据等量齐观地进行处理，故在异方差的情况下不是最有效率的[^工具变量法（四）：GMM]。     

　　在过度识别且存在异方差的情况下，更有效率的做法是“广义矩估计”（Generalized Method of Moments，简记 GMM）。该方法由芝加哥大学的 Lars Peter Hansen 教授所提出 (Hansen, 1982)，已成为最流行的计量方法之一，Hansen也因此获得 2013年的诺贝尔经济学奖。顾名思义，广义矩估计为矩估计的推广，故先介绍矩估计。          

　　假设待估参数的个数为$K$，矩条件的个数为$L$ 。当$L=K$时，称为“恰好识别”，当$L>K$时，称为 “过度识别”。

　　GMM是矩估计（MM）的推广。在恰好识别情况下，目标函数的最小值等于 0 ，GMM 估计量与 MM 估计量等价；然而在过度识别情况下，MM 不再适用，GMM 可以有效地组合矩条件，使 GMM 比 MM 更有效。GMM 建立在期望值和样本平均值的基础上。矩条件是用真实矩指定模型参数的期望值。



## 动态面板数据      

　　GMM的经典用法在动态面板数据(Dynamic Panel data, DPD)分析中，所指的是分析中采用如下的回归方程：
$$
Y_{i, t}=\alpha Y_{i, t-1}+\beta X_{i t}+u_{i}+\varepsilon_{i t} \tag{1}
$$

　　 其中，$Y_{i,t-1}$是因变量的滞后项，$u_{i}$是个体$i$的固定效应。<font color=blue> 因变量的滞后项和固定效应同时存在，是动态面板数据分析特殊性的关键。</font>如果固定效应不存在，那么回归方程变为:
$$
Y_{i, t}=\alpha Y_{i, t-1}+\beta X_{i t}+\varepsilon_{i t}  \tag{2}
$$
　　 这时，用OLS或者随机效应模型回归分析即可。如果因变量的滞后项 $\alpha Y_{i,t-1}$不存在，那么回归方程变为：  
$$
Y_{i, t}=\beta X_{i t}+u_{i}+\varepsilon_{i t} \tag{3}
$$

　　 对于该模型，用固定效应模型分析即可。如果因变量的滞后项和固定效应都存在，那么对于（1）式这样的回归方程，如果采用<font color=blue >**OLS或者FE均存在内生性问题（即系数的估计值是有偏的）**</font>。如果使用OLS估计，由于以下公式（4）和公式（1）均存在固定项$u_{i}$,即存在内生性：
　　 
$$
Y_{i, t-1}=\beta X_{i t-1}+u_{i}+\varepsilon_{i t-1} \tag{4}
$$

　　 如果采用差分方法去掉固定效应，会得到如下的结果:
$$
\Delta Y_{i,t}=\alpha \Delta Y_{i,t-1}+\beta\Delta X_{i,t}+\Delta \epsilon_{i,t}  \tag{5}
$$
　　 其中，$\Delta Y_{i, t}=Y_{i, t}-Y_{i, t-1}$, $\quad \Delta Y_{i, t-1}=Y_{i, t-1}-Y_{i, t-2}$, $\quad \Delta X_{i, t}=X_{i, t}-X_{i, t-1}$, $\quad \Delta \varepsilon_{i, t}=\varepsilon_{i, t}-\varepsilon_{i, t-1}$。如果（1）式代表了真实的变量之间关系，那么$\Delta Y_{i, t-1}$和$\Delta \varepsilon_{i, t}$之间必有相关性，因为：
$$
\Delta Y_{i, t-1}=Y_{i, t-1}-Y_{i, t-2}=(\alpha-1) Y_{i, t-2}+\beta X_{i, t-1}+\varepsilon_{i, t-1}\tag{6}
$$
　　 $cov(\Delta Y_{i,t-1},\Delta \epsilon_{i,t})$显然不会等于0，因为两者都有$\varepsilon_{i, t-1}$这一项。通常所用的固定效应模型实际上就是对（1）式差分，得到类似于（5）式的差分回归方程，然后做OLS。对于现在的情况，由于$\Delta Y_{i, t-1}$和$\Delta \varepsilon_{i, t}$之间的相关性，再用OLS只会得到有偏误的回归系数。所以传统的统计方法无法实现对此类方程的估计，需要用GMM方法。

> 　　<font face="思源宋体 CN" >需要注意的是（2）的模型（包含滞后项的OLS）和（3）的模型（不包含滞后项的FE，固定效应）尽管都有偏误,但好处是一个偏大,一个偏小(具体哪个大,哪个小要看变量之间的关系),所以这两个估计系数应该界定了真实参数的范围（Angrist and Pischke，2009:246页；Roodman，2009）。也就是说，你最后用GMM方法估计出来的参数应该落到这个区间。</font>



　　

# 基本思想  

　　广义矩估计 (Generalized Method of Moment, 简称 GMM) 是一种构造估计量的方法，类似于极大似然法 (MLE) 。MLE 通过假设随机变量服从特定的分布，进而将待估参数嵌入似然函数，通过极大化联合概率密度函数得到参数的估计值。<font color=blue>GMM 则是以随机变量遵循特定矩的假设，而不是对整个分布的假设，这些假设被称为矩条件</font>。这使得 GMM 比 MLE 更稳健，但会导致估计量的有效性有所降低 (估计出的标准误比较大)[^Stata：GMM-简介及实现范例]。

[^Stata：GMM-简介及实现范例]:[Stata：GMM-简介及实现范例](https://www.lianxh.cn/news/56e2f8913175e.html)

#  矩 (Moment)  

　　何为矩？简单说，矩就是<font color = blue>随机变量之函数的期望</font>。比如，对于随机变量  ，其一阶原点矩为其期望$E(x)$ ，二阶中心矩为其方差$\operatorname{Var} \equiv \mathrm{E}[x-\mathrm{E}(x)]^{2}$，以此类推。

　　更一般地，考虑随机变量$x$的函数$f(x)$。显然，$f(x)$仍为随机变量，其期望$E[f(x)]$
 也称为“矩”（moment）。

　　进一步推广，随机向量$x$的函数$f(x)$之期望$E[f(x)]$，也称为 “矩”。总之，矩可以视为随<font color = blue>机变（向）量的某种特征</font>

# 矩估计量（MM估计量）

## 期望与方差的矩估计

$$
E(\mathrm{y}-\mu)=0 \rightarrow \frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{\mu}\right)=0 \rightarrow \hat{\mu}=\frac{1}{N} \sum_{i=1}^{N} y_{i}\tag{7}
$$

　　其中， $N$表示样本数， $y_{i}$表示 $y$ 的第 $i$ 个观察值 。此处，估计量$\hat{\mu}$ 被称为矩估计量( the method of moments estimator )，简称 MM 估计量。这是因为，该估计量的构造以母体矩条件( population moment condition )为基础，进而用其样本矩条件（依赖于我们使用的数据）做等价代换。因为我们从总体矩条件开始，然后运用类比原理得到一个依赖于观测数据的估计量。
 我们想要估计随机变量 ${Y}$的均值，即 $\mu=E[\mathrm{y}]$，其中“母体矩条件( PMC )”为：
$$
 E[\mathrm{y}]-\mu=0  \tag{8}
$$


　　$\left\{y_{1}, y_{2}, \dots, y_{n}\right\}$为从这个母体中随机抽取的一组样本观察值，则对应的“样本矩条件( SMC )”为
$$
\frac{1}{N} \sum_{i=1}^{N} y_{i}-\hat{\mu}=0 \tag{9}
$$
　　因此，我们可知母体矩条件的样本均值估计为： $\mu=E[\mathrm{y}]$ ，样本矩条件的样本均值估计为： $\hat{\mu}=\frac{1}{N} \sum_{i=1}^{N} y_{i}$ 。

> 例子：

　　自由度为 $k$的 $\chi^{2}$ 随机变量的均值为 $k$，方差为 $2k$，因此两个母体矩条件( PMC )如下：
$$
E[Y-k]=0 \qquad \tag{10a}
$$

$$
E\left[(Y-k)^{2}-2 k\right]=0 \qquad \tag{10b}
$$


　　这个母体中随机抽取的一组样本观察值 $\left\{y_{1}, y_{2}, \ldots, y_{n}\right\}$，对应的样本矩条件( SMC )为：
$$
\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{k}\right)=0 \quad \tag{11a}
$$


$$
\frac{1}{N} \sum_{i=1}^{N}\left[\left(y_{i}-\hat{k}\right)^{2}-2 \hat{k}\right]=0 \tag{11b}
$$



> 　　矩估计法是用样本的 $k$阶矩作为总体的 $k$阶矩的估计量，建立含待估计参数的方程，从而可解出待估计参数。一般地，不论总体服从什么分布，总体期望 $\mu$ 与方差 $\sigma^{2}$ 存在，则根据据估计法，它们的矩估计量分别为：

$$
\hat{\mu}=\frac{1}{n} \sum_{i=1}^{n} X_{i}=\overline{X} \tag{12a}
$$

$$
\hat{\sigma}^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2} \tag{12b}
$$

## 简单线性回归的矩估计

### 简单线性回归的矩条件

　　OLS 估计可以视为矩估计的一个特例。OLS 估计的公式为：
$$
y_{i}=\beta x_{i}+\mu_{i} \tag{13}
$$
　　其中，$x_{i}$与 $\mu_{i}$不相关，则有 $E\left[\mu_{i} | x_{i}\right]=0$。因此，
$$
E\left[\mu_{i} | x_{i}\right]=0 \rightarrow E\left[y_{i}-\beta x_{i} | x_{i}\right]=0 \rightarrow E\left[x_{i}\left(y_{i}-\beta x_{i}\right)\right]=0 \tag{14}
$$
　　其中，$E\left[x_{i}\left(y_{i}-\beta x_{i}\right)\right]=0$ 是母体矩条件，对应的样本矩条件为：
$$
\frac{1}{N} \sum_{i=1}^{N}\left[x_{i}\left(y_{i}-\hat{\beta}^{M M} x_{i}\right)\right]=0 \tag{15}
$$
　　求解即可得到 OLS 估计下的 $\hat{\beta}^{M M}$ 。

### Stata实现

- OLS估计

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
regress mpg gear_ratio turn,vce(robust)

```
- GMM估计


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
gmm (mpg - {b1}*gear_ratio - {b2}*turn - {b0}),instruments(gear_ratio turn)

```

- 利用线性组合的简单线性GMM估计


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
gmm (mpg - {xb:gear_ratio turn} - {b0}), instruments(gear_ratio turn)

```



##   工具变量法的MM与GMM估计

### 工具变量法的原理

　　工具变量的思想其实很简单。虽然内生变量$x$是“坏”的变量（与扰动项相关），但仍可能有“好”的部分（与扰动项不相关的部分），正如坏人通常也有好的一面。如果能将内生变量*$x$*分解为内生部分与外生部分之和，则可能使用其外生部分得到一致估计[^工具变量法（一）]。       


　　而要实现这种分离，通常需要借助另一变量，比如**$z$**，称为 “工具变量”（Instrumental Variable，简记 IV），因为它起着工具性的作用。



[^工具变量法（一）]:[工具变量法（一）：2SLS](https://mp.weixin.qq.com/s/CxzYLg3kNzp_WGCZhWtUYg)

　　显然，并非任何变量都可以作为工具变量。首先，变量$z$要能够帮助内生变量$x$分离出一个外生部分，则变量$z$自身必须是“干净”的，即满足“外生性”（$z$与扰动项$\varepsilon$不相关）：  
$$
Cov(z_{i},\varepsilon_{i})=0 \tag{16}
$$
　　其次，变量$z$还须与$x$有一定关系，即满足“相关性”:      
$$
Cov(z_{i},x_{i})\not =0  \tag{17}
$$

　　**工具变量法中，假设待估参数的个数为$k$，矩条件的个数为$l$：**    

- 1.无法识别（unidentified）：当 $k > l$ 时，即工具变量个数少于内生变量个数，则无法进行2SLS      估计，称为“不可识别”（unidentified），因为无法得到对模型参数的一致估计；      

- 2.恰好识别( just or exactly identified )：当 $k = l$ 时；  

- 3.过度识别( overidentified )：当 $k < l$时，即待估参数个数小于工具变量的个数。  



### 工具变量法：两阶段最小二乘估计（2SLS）

　　**两阶段最小二乘法其本质上是属于工具变量，回归分两个阶段进行，因此而得名。具体机理是：[^Stata：GMM-简介及实现范例]**   

- 第一步，将结构方程先转换为简化式模型（约简型方程），简化式模型里的每一个方程都不存在随机解释变量问题，可以直接采用普通最小二乘法进行估计。    

- 第二步，由第一步得出的 $\hat{Y}$的估计量替换 $Y$。该方程中不存在随机解释变量问题，也可以直接用普通最小二乘法进行估计。    


　　例子：一般 IV 回归模型为：
$$
Y_{i}=\beta_{0}+\beta_{1} X_{1 i}+\ldots+\beta_{k} X_{k i}+\beta_{k+1} W_{1 i}+\ldots+\beta_{k+r} W_{r i}+u_{i} (i=1,2, \ldots, n) \tag{18}
$$

   -  其中：
      - $Y_{i}$为因变量；
      - $u_{i}$为误差项，表示测量误差和/或遗漏因素；
      - $X_{1 i} , X_{2 i} , \ldots , X_{k i}$表示k个内生回归变量，可能与 $u_{i}$相关；
      - $W_{1 i} , W_{2 i}, \ldots , W_{r i}$ 表示 r 个包含的外生变量，与 $u_{i}$ 不相关；
      - $\beta_{0} , \beta_{1} , \ldots , \beta_{k+r}$ 为未知回归系数；
      - $Z_{1 i} , Z_{2 i} , \ldots , Z_{m i}$为 $m$ 个工具变量。

　　以单内生回归变量的 2SLS 为例，当只有一个内生回归变量 $X$和一些其他的包含的外生变量时，感兴趣的方程为：
$$
Y_{i}=\beta_{0}+\beta_{1} X_{i}+\beta_{2} W_{1 i}+\ldots+\beta_{k+r} W_{r i}+u_{i} \tag{19}
$$
　　其中同前 $X_{i}$ 可能与误差项相关，但 $W_{1 i}, W_{2 i}, \ldots, W_{r i}$与误差项不相关。

　　2SLS 的总体第一阶段回归将 $X$ 与外生变量 $W$和工具变量（$Z$）联系在了一起：
$$
X_{i}=\pi_{0}+\pi_{1} Z_{1 i}+\ldots+\pi_{m} Z_{m i}+\pi_{m+1} W_{1 i}+\ldots+\pi_{m+r} W_{r i}+v_{i}  \tag{20}
$$
　　其中 $\pi_{0} , \pi_{1} , \ldots , \pi_{m}$为未知回归系数， $v_{i}$为误差项。

　　在 2SLS 的第一阶段中，可用 OLS 估计（ 20）式中的未知系数，并记由该回归得到的预测值为$\hat{X}_{1}, \hat{X}_{2}, \ldots, \hat{X}_{n}$ 。

　　在 2SLS 的第二阶段中，用 OLS 估计的 $X_{i}$ 的预测值替换（19）式。也就是用 OLS 估计 $Y_{i}$关于 $\hat{X}_{i}$，$W_{1 i}, W_{2 i}, \ldots, W_{r i}$的回归。得到的 $\beta_{0}, \beta_{1}, \ldots, \beta_{1+r}$估计量就是 2SLS 估计量。

　　当存在多个内生回归变量 $X_{1 i}, X_{2 i}, \dots, X_{k i}$时，除了每个内生回归变量都需要自己的第一阶段回归以外， 2SLS 的算法是类似的。其中每个内生回归变量的第一阶段回归形式同（20）式，即因变量是某个 $X$，回归变量是所有工具变量（ $Z$）和所有包含的外生变量（$W$）。所有这些第一阶段回归一起得到了每个内生回归变量的预测值。

　　在 2SLS 的第二阶段中，用 OLS 估计内生回归变量（$X$），分别用其预测值（$\hat{X}$）替换后的（18）式。得到的$\beta_{0}, \beta_{1}, \beta_{2}, \dots, \beta_{k+r}$估计量即为2SLS估计量。

　　<font color=blue >如果扰动项为球形扰动项（满足同方差、无自相关），则2SLS为最有效率的工具变量法。如果担心扰动项存在异方差，则依然可使用稳健标准误（robust standard errors）进行统计推断。</font>



### 工具变量法的矩估计（MM）

　　在恰好识别的情况下，可将矩估计运用于工具变量法[^工具变量法（四）：GMM]。考虑以下多元回归模型，共有个$K$个未知参数，

[^工具变量法（四）：GMM]:[工具变量法（四）：GMM](https://mp.weixin.qq.com/s/aSbHlvAlcWiT6CnCpW1L6Q)

　　
$$
\mathrm{y}_{i}=\beta_{1} x_{i 1}+\cdots+\beta_{\mathrm{K}} x_{i \mathrm{k}}+\varepsilon_{i} \quad(i=1, \ldots, n) \tag{21}
$$

　　 其中，第一个解释变量一般为常数项，即$x_{i,t}\equiv1$。更紧凑地，此方程可写为：
$$
\mathbf{y_{i}}=\mathbf{x_{i}}^{'} \boldsymbol{\beta}+\boldsymbol{\varepsilon_{i}} \tag{22}
$$
　　其中，$\mathbf{x_{i}}^{\prime}$与$\boldsymbol{\beta}$均为$K$维列向量。在恰好识别的情况下，记由所有工具变量所构成的向量为$\mathbf{z_{i}}^{'}$（可以与$\mathbf{x_{i}}^{\prime}$有重叠，即外生变量作为自己的工具变量），也是$K$维列向量。由这些工具变量所提供的识别模型的总体矩条件为：

$$
\mathrm{E}\left(\mathbf{z}_{i} \varepsilon_{i}\right)=\mathrm{E}\left[\left(\begin{array}{c}
z_{11} \\
\vdots \\
z_{i k}
\end{array}\right) \varepsilon_{i}\right]=\left(\begin{array}{c}
0 \\
\vdots \\
0
\end{array}\right)=0    \tag{23}
$$
　　 此<font color=blue >总体矩条件也被称为“正交条件”（orthogonality conditions）</font>在数理统计中，如果两个随机变量的乘积之期望为0，则称这两个随机变量正交。

　　 显然，<font color=blue >如果两个随机变量中包含一个随机扰动项，则 “两个随机变量不相关” 就等价于 “两个随机变量正交”</font>，比如：  
$$
0=\operatorname{Cov}\left(z_{i }, \varepsilon_{i}\right)=\mathrm{E}\left(z_{i } \varepsilon_{i}\right)-\mathrm{E}\left(z_{i }\right) \underbrace{\mathrm{E}\left(\varepsilon_{i}\right)}_{=0}=\mathrm{E}\left(z_{i } \varepsilon_{i}\right)=0
$$
　　其中，扰动项$\varepsilon_{i}$的期望为0（只要回归方程有常数项，总可以将扰动项的非零期望归入常数项）。由于$\varepsilon_{i}={y_{i}}-\mathbf{x_{i}}^{'} \boldsymbol{\beta}$，将此表达式代入上式的正交条件，可得更便于估计的总体矩条件：
$$
\mathrm{E}\left[\mathbf{z}_{i}\left(y_{i}-\mathbf{x}_{i}^{\prime} \beta\right)\right]=\mathbf{0} \tag{24}
$$
　　以样本矩替代总体矩可得：
$$
\mathbf{g}_{n}(\hat{\beta}) \equiv \frac{1}{n} \sum_{i=1}^{n}\left[\mathbf{z}_{i}\left(y_{i}-\mathbf{x}_{i}^{\prime} \hat{\beta}\right)\right]=\mathbf{0}  \tag{25}
$$
　　这是一个由$K$个方程（$\mathbf{z_{i}}$的维度）、$K$个未知数（$\beta$的维度）所构成的线性联立方程组，故一般情况下存在唯一解，即矩估计量（Method of Moments，简记MM）。<font color=blue> 可以证明，此MM 估计量等价于2SLS。</font>

### 工具变量法的广义矩估计（GMM）


> 　　在恰好识别情况下，目标函数的最小值等于 0 ，GMM 估计量与 MM 估计量等价；然而，在过度识别的情况下，却无法使用传统的矩估计。这是因为，此时$\mathbf{z_{i}}$的维度大于$\beta$的维度，对参数向量$\beta$有过多的约束，使得方程个数大于未知数个数，导致此线性方程组无解。  

> 　　由于在恰好识别的情况下，矩估计等价于2SLS；而在过度识别的情况下，矩估计不适用而2SLS依然可行，故传统上工具变量法一般用2SLS。  

> <font color=blue>  　　然而在过度识别情况下，MM 不再适用，GMM 可以有效地组合矩条件，使 GMM 比 MM 更有效。</font>
  
####  Lars Hansen的脑筋急转弯

　　看似已走入死胡同的矩估计，却被 Lars Hansen起死回生了。假设工具变量$\mathbf{z_{i}}$的维度$L$，且严格大于参数向量$\beta$$\beta$的维度 。如上所述，此时样本矩的线性方程组无解。这意味着，找不到$\hat{\beta}$，能够使得上述样本矩等于0向量。　　

　　但Lars Hansen来了个脑筋急转弯：虽然无法找到$\hat{\beta}$，使得样本矩等于0，但总可以让样本矩尽量接近于0。由于样本矩$\mathbf{g}_{n}(\hat{\beta})$为$L$维列向量，故可用二次型来衡量它到0向量的距离，比如最小化如下目标函数：　　


$$
\min _{\hat{\beta}}\left(\mathbf{g}_{i}(\beta)\right)\left(\mathbf{g}_{n}(\beta)\right) \tag{26}
$$
　　这个脑筋急转弯价值不菲，三十多年后为Lars　Hansen带来了诺贝尔奖。更一般地，可用一个“权重矩阵”（weightingmatrix）（可依赖于样本）来构成二次型，定义最小化的目标函数为：  
　　
$$
\min _{\tilde{\beta}} J(\beta, \mathbf{W}) \equiv n\left(\mathbf{g}_{n}(\beta)\right) \mathbf{W}\left(\mathbf{g}_{n}(\beta)\right) \tag{27}
$$
　　其中，因子$n$不影响最小化。这是一个无约束的最优化问题，目标函数$J(\hat{\beta}, \widehat{\mathbf{W}})$是$\hat{\beta}$的二次（型）函数，故可得到其解析解（推导方法类似于 OLS），即 “GMM估计量”。  

　　在恰好识别的情况下，目标函数的最小值正好为0，故GMM估计量等价于MM估计量（故也等价于 2SLS），因此 GMM 确实是 MM 的推广。

#### 矩条件的强弱

　　显然，GMM 估计量取决于权重矩阵。对于$\widehat{\mathbf{W}}$的灵活选择是GMM 的最大优点之一，因为不同矩条件的强弱程度一般不同。矩条件只是说明$\mathrm{E}(z_{i } \varepsilon_{i})=0$，但每个矩条件的方差$\mathrm{Var}(z_{i } \varepsilon_{i})$可以不同，参见右图[^矩条件的强弱]。
  
[^矩条件的强弱]:![矩条件的强弱](https://gitee.com/shao818/Figure/raw/master/null/image-20201118160559634.png)


$$
\mathbf{Y}=\mathbf{X} \boldsymbol{\beta}+\boldsymbol{\varepsilon}
$$
      一个强的矩条件意味着其对应的方差较小（上图实线，矩条件1），是一个比较紧的约束，包含更大的信息量，故会通过$\widehat{\mathbf{W}}$  得到较大的权重，使得GMM估计量更有效率。具体来说，矩条件的协方差矩阵可写为：  
      
$$
\mathbf{S} \equiv \operatorname{Var}\left(\mathbf{z}_{i} \varepsilon_{i}\right)=\mathrm{E}\left(\varepsilon_{i}^{2} \mathbf{z} \mathbf{z}_{i}^{\prime}\right) \tag{28}
$$
     以残差（比如$e_{i}$，2SLS残差，因为2SLS也是一致的）替代上式的扰动项$\varepsilon_{i}$，并以样本均值替代总体期望，可得对此协方差矩阵的一致估计
$$
\hat{\mathbf{S}} \equiv \frac{1}{n} \sum_{i=1}^{n} e_{i}^{2} \mathbf{z} \mathbf{z}_{i} \tag{29}
$$
    Hansen (1982)证明，如果让$\widehat{\mathbf{W}}=\hat{\mathbf{S}}^{-1}$  （方差矩阵的逆矩阵或“倒数”），则可使得 GMM 估计量的渐近方差最小化，其相应的GMM估计量称为“最优GMM”（optimal GMM）。自然地，既然存在最优GMM，一般就不会使用其他的权重矩阵了，故一般所说的GMM估计量默认就是最优GMM。

- 更详细的解释：

$$
\mathbf{Y}=\mathbf{X} \boldsymbol{\beta}+\boldsymbol{\varepsilon}  \tag{30}
$$

　　其中， $Z$是工具变量，$E(\varepsilon|Z）=0。X=(x_{1},x_{2},...,x_{k}))$ ，是 $k$个自变量向量，$Z=(z_{1},z_{2},...,z_{k})$是 个工具变量向量。相应的，待估计的系数 $\beta$是$k$维向量。定义$E=Y-X\beta$为误差向量，对于任意估计出来的参数 $\hat{\beta}$ ，残差项为$\hat{E}=Y-X\hat{\beta}$。

　　根据工具变量的含义，它应该和误差项$\epsilon$独立：$E(Z^{'}\varepsilon)=0$，这就是我们需要的矩条件。计算的时候，理论上应该利用 $E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right) \equiv \frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}=0$求解，注意到，我们有$j$ 个工具变量，也就是$j$个矩条件（$j$个方程）。理论上，需要根据这$j$个方程求解$k$个待估计的参数。但是不幸的是，如果工具变量的数量 小于待估计的参数数量 ，方程是不可识别的——通常不可能通过2个方程解出3个未知数。如果工具变量等于待估计的参数，是恰好可识别的，但这种情况在GMM中很难碰到。最常见的是工具变量多于待估计的参数，即 $j>k$，这意味着要找$k$个参数，让$j$个方程同时等于零。这难度相当大，实际上大多数时候找不到，怎么办呢？在矩估计里面，采用的办法是，找$k$个参数，让$E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right) \equiv \frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}$和零之间的距离最小。实际计算的时候，需要借助一个半正定的矩阵 $A$，计算向量 $E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right) \equiv \frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}$的模：
$$
\left\|E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right)\right\|_{\mathbf{A}} \equiv\left\|\frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}\right\|_{\mathbf{A}}=N\left(\frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}\right)^{\prime} \mathbf{A}\left(\frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}\right)=\frac{1}{N} \hat{\mathbf{E}}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z}^{\prime} \hat{\mathbf{E}}  \tag{31}
$$
　　目标变成，寻找参数向量$\hat{\boldsymbol{\beta}}_{\mathbf{A}}=\arg \min \left\|E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right)\right\|_{\mathbf{A}}$，这就要用到一阶条件等于零：
$$
\frac{d\left\|E_{N}\left(\mathbf{Z}^{\prime} \varepsilon\right)\right\|_{A}}{d \hat{\beta}}=\ldots=\frac{2}{N} \hat{\mathbf{E}}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z}^{\prime}(-\mathbf{X})=0  \tag{32}
$$
　　计算的过程利用到了连锁规则和向量求导的公式。继续推导，把$\hat{E}=Y-X\hat{\beta}$带入，得

到：
$$
\begin{array}{c}
0=\hat{\mathbf{E}}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z} \mathbf{X}=(\mathbf{Y}-\mathbf{X} \hat{\boldsymbol{\beta}})^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z} \mathbf{X}=\mathbf{Y}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z}^{\prime} \mathbf{X}-\hat{\boldsymbol{\beta}}^{\prime} \mathbf{X}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z} \mathbf{X} \\
\hat{\boldsymbol{\beta}}_{\mathbf{A}}=\left(\mathbf{X}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Z} \mathbf{A} \mathbf{Z}^{\prime} \mathbf{Y}
\end{array}  \tag{33}
$$
　　这就是$\beta$的GMM估计量，这个估计量是有偏的，它的期望值不等于真实的$\beta$；然而它是一致的，当样本量足够大的时候，它会接近真实的$\beta$。这个估计量和$A$有关，但是$A$只影响参数估计的有效性——不同的A对应的参数 $\hat{\boldsymbol{\beta}}_{\mathbf{A}}$收敛的速度不同。这里的A其实是对不同的矩条件加以不同的权重，可以找到一个收敛最快的A，称为 $A_{EGMM}$，可以证明：$\mathbf{A}_{E G M M}=\operatorname{Var}(\mathbf{z} \varepsilon)^{-1}$。

　　对于工具变量法常用的两阶段最小二乘法（2SLS），如果假定误差项是独立同分布，那么$\mathbf{A}_{E G M M}=\operatorname{Var}(\mathbf{z} \varepsilon)^{-1}=(Z^{'}Z)^{-1}$，此时
$$
\hat{\boldsymbol{\beta}}_{G M M}=\left(\mathbf{X}^{\prime} \mathbf{Z}(\mathbf{Z} \mathbf{Z})^{-1} \mathbf{Z} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Z}(\mathbf{Z} \mathbf{Z})^{-1} \mathbf{Z}^{\prime} \mathbf{Y} \tag{34}
$$
　　这实际上就是传统通过两阶段最小二乘法（2SLS）估计出来的参数，殊途同归。

### 工具变量法的过度识别检验

>在过度识别的情况下，则可以进行 “过度识别检验”（overidentification test）。考虑以下原假设：
>$$
>H_{0}:所有工具变量都是外生
>$$
>其实，这就是检验总体矩条件是否成立：
>$$
>H_{0}:\mathrm{E}\left(z_{i } \varepsilon_{i}\right)=0
>$$

#### 2SLS过度识别检验

- Sargan统计量　　

　　上面提到了，只有恰好识别和过度识别才能用 IV 方法估计。假设待估参数的个数为 $k$，矩条件的个数为 $l$。当 $k=l$ 时，称为“恰好识别”，当 $k<l$时，称为 “过度识别”。

<font color=blue>　　一个很重要的命题是：只有过度识别情况下才能检验工具变量的外生性，而恰好识别情况下无法检验。</font>

　　具体思路如下：工具变量的外生性意味着它们和 $\mathrm{u}_{\mathrm{i}}$不相关。这表明工具变量和 $\hat{\mathrm{u}}_{\mathrm{i}}^{2 \mathrm{SLS}}$ 近似不相关，其中
$$
\hat{\mathrm{u}}_{\mathrm{i}}^{2 S L S}=Y_{i}-\left(\hat{\beta}_{0}^{2 S L S}+\hat{\beta}_{1}^{2 S L S} X_{1 i}+\ldots+\hat{\beta}_{k+r}^{2 S L S} X_{r i}\right) \tag{35}
$$
　　为基于所有工具变量的 2SLS 回归估计残差（由于抽样变异性因此是近似的而不是精确地，注意到这些残差是利用 $X$ 值而不是用其第一阶段的预测值得到的。）

　　于是，如果工具变量事实上是外生的，那么 $\hat{\mathrm{u}}_{\mathrm{i}}^{2 \mathrm{SLS}}$ 关于工具变量和包含的外生变量回归中工具变量的系数都应该等于零，而这个假设是可以检验的。

　　过度识别约束检验（ J 统计量），又称为 Sargan 统计量。令 $\hat{\mathrm{u}}_{\mathrm{i}}^{2 \mathrm{SLS}}$为来自（22）式 2SLS 估计的残差。

　　利用 OLS 估计下面的回归系数：
$$
\hat{u}_{i}^{2 S L S}=\delta_{0}+\delta_{1} Z_{1 i}+\ldots+\delta_{m} Z_{m i}+\delta_{n t+1} W_{1 i}+\ldots+\delta_{m+r} W_{n}+e_{i}  \tag{36}
$$

>  　　其中， $e_{i}$为回归误差项。令 F表示检验假设$\delta_{1}=\ldots=\delta_{m}=0$的同方差适用 F 统计量。则过度识别约束检验统计量为 $J=mF$。如果 $e_{i}$ 是同方差的，则在所有工具变量都是外生的原假设下， $J$服从 $\chi_{m-k}^{2}$分布，其中 $m-k$ 为“过度识别度”，也就是工具变量的个数减去内生回归变量的个数。

- 沃尔德检验（Wald Test）

　　记所有工具变量所构成的向量为$\mathbf{z_{i}}$（包含工具变量与外生解释变量），则所有工具变量皆外生的原假设可写为以下“总体矩条件”（population moment conditions）：
$$
H_{0}:\mathrm{E}\left(z_{i } \varepsilon_{i}\right)=0 \tag{37}
$$
　　即工具变量$\mathbf{z_{i}}$与扰动项$\varepsilon_{i}$正交。根据样本数据，可得其相应的“样本矩”（sample moments），记为$\mathbf{g}_{n}$其中下标$n$表示样本容量；而且如果总体矩条件正确，则样本矩也应该离0向量不远：
$$
\mathbf{g}_{n} \equiv \frac{1}{n} \sum_{i=1}^{n} \mathbf{z}_{i} e_{i} \approx \mathbf{0} \tag{38}
$$
　　为了度量此距离，可构造如下二次型来检验原假设：
$$
\mathbf{g}_{n}^{\prime}\left[\widehat{\operatorname{Var}\left(\mathbf{g}_{\mathrm{n}}\right)}\right]^{-1} \mathbf{g}_{n} \rightarrow \chi^{2}(L-K) \tag{39}
$$
　　其中，二次型矩阵为样本矩$\mathbf{g}_{n}$之协方差矩阵估计量的逆矩阵。

>　　事实上，在过度识别的情况下，通常使用更有效率的广义矩估计（Generalized Method of Moments，简记 GMM）。故现在一般使用GMM的Hansen's J统计量来进行过度识别检验，原理与上述Wald检验类似。       
>　　需要特别说明的是，无论使用何种过度识别检验，都有一个不检验的大前提（maintained hypothesis），即模型至少是恰好识别的。因此，即使检验结果接受了“所有工具变量皆外生”的原假设，也并不表示就证明了所有工具变量的外生性。它只是表明，在模型恰好识别的情况下，多余的那些工具变量也是外生的。        
>　　总之，根据目前的计量经济学，工具变量的外生性在本质上依然是不可检验的，学者们仍需围绕“排他性约束”而进行定性讨论，甚至无休止的争论。        

#### GMM方法的过度识别检验

- Hansen统计量

　　前文已经介绍，使用GMM方法的目标是选择参数，最小化$E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right) \equiv \frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}$和零之间的距离$\left\|E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right)\right\|_{A}$。那么问题来了，多小算小呢？会不会是最小值也显著大于零？如果这样的话，方法的适用性就成问题。也就是说，根据你估计出来的参数，算出的残差项实际上和工具变量不是独立。Hansen检验和Sargan检验的逻辑就是，以$\left\|E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right)\right\|_{A}$最小化为目标，估计出参数，然后把参数带入，看看它是否真的等于零。如果统计上不能拒绝它等于零，则所用工具变量可靠；如果统计上拒绝它等于零，则不可靠。

　　如果零假设成立（即 $H_{0}$：工具变量是联合有效的），那么 $E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right) \equiv \frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}$应随机分布于零附近，它和零的距离应服从$\chi^{2}$分布：  
$$
\left\|E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right)\right\|_{\mathbf{A}_{\mathrm{EGMM}}} \equiv\left\|\frac{1}{N} \mathbf{Z}^{\prime} \hat{\mathbf{E}}\right\|_{\mathbf{A}_{\mathrm{EGM}}}=\frac{1}{N} \hat{\mathbf{E}}^{\mathbf{\prime}} \mathbf{Z} \mathbf{A}_{\mathrm{EGMM}} \mathbf{Z}^{\prime} \hat{\mathbf{E}} \sim \chi^{2}_{j-k} \tag{40}
$$
　　这就是Hansen统计量，它服从自由度为$j-k$的$\chi^{2}$分布，这里自由度其实就是过度识别的维度。在实际使用中，不应该显著（p值小于0.1）；如果显著，则表明拒绝了零假设，工具变量不是联合有效的。

> 　　 然而，需要注意的是，如果使用的工具变量太多，那么Hansen统计量会非常不显著，常常等于1。这是因为，$j-k$越大，意味着分布显$\chi^{2}$著的门槛越高（请查阅$\chi^{2}$分布的表格）。也就是说，工具变量太多，会让Hansen检验的效果变弱，这是需要注意的。通常Hansen检验的p值大于0.25就要小心了，这时需要考虑减少工具变量的数量。       

- Sargan 检验的统计量

　　 Sargan 检验的统计量类似，只不过把Hansen统计量中的$A_{EGMM}$ 替换成了 $(\mathbf{Z} \mathbf{Z})^{-1} $，即
$$
S=\left\|E_{N}\left(\mathbf{Z}^{\prime} \boldsymbol{\varepsilon}\right)\right\|_{\left(z^{\prime} z\right)^{-1}}=\frac{1}{N} \hat{\mathbf{E}}^{\prime} \mathbf{Z}(\mathbf{Z} \mathbf{Z})^{-1} \mathbf{Z}^{\prime} \hat{\mathbf{E}} \sim \chi_{j-k}^{2}\tag{41}
$$

> 　　 然而，该统计量有时候是不一致的，如果在命令中要求报告稳健的Sargan统计量，软件会做两阶段GMM估计（先找任意合理的H，令 $\mathbf{A}=\left(\mathbf{Z}^{\prime} \mathbf{H} \mathbf{Z}\right)^{-1}$，估计出第一步参数 $\hat{\beta_{1}}$；再根据$\hat{\beta_{1}}$，计算出残差项的方差-协方差矩阵$\hat{\Omega}_{\hat{\beta}_{1}}$ ，令 $\mathbf{A}=\left(\mathbf{Z}^{\prime} \hat{\Omega}_{\hat{\beta}_{1}} \mathbf{Z}\right)^{-1}$，估计出第二部参数 $\hat{\beta_{1}}$），根据第二步的参数结果，默默报告出Hansen统计量。整体上说，Hansen统计量好像更靠谱一点，所以报告的时候，更多关注Hansen统计量。


### Stata实现

#### 两阶段最小二乘估计(一步GMM估计)

- 两阶段最小二乘估计(2SLS)

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
*工具变量两阶段最小二乘(2SLS)
ivregress 2sls mpg gear_ratio (turn = weight length headroom)
*过度识别检验
estat overid
```

- 一步GMM估计

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
gmm (mpg - {b1}*turn - {b2}*gear_ratio - {b0}), instruments(gear_ratio weight length headroom) onestep
```

>　　可以看到，两阶段最小二乘( `ivregress 2sls` )与GMM的一步估计（`gmm onestep`）结果完全相同。

#### 工具变量GMM估计（两步 GMM 估计）

- 工具变量GMM估计

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
*工具变量GMM估计
ivregress gmm mpg gear_ratio (turn = weight length headroom)
*过度识别检验
estat overid
```

- 两步 GMM 估计

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysuse auto,clear
gmm (mpg - {b1}*turn - {b2}*gear_ratio - {b0}),  ///
     instruments(gear_ratio weight length headroom) wmatrix(robust)
```

>可以看到，两阶段最小二乘的GMM估计( `ivregress gmm` )与GMM的二步估计（`gmm twostep`）结果完全相同。



###  GMM 过程的 Stata 命令说明



　　在 Stata 中， gmm 的一般命令形式为：

```stata
 gmm  ([reqname1:]rexp_1)  ([reqname2:]rexp_2) . . . [if] [in] [weight] [,options]
```

　　其中：

- `reqname_j` 代表第 j 个剩余方程的表达式
- `rexp_j` 是第 j 个残差方程的可替换表达式

GMM 的矩估计命令形式为：

```stata
gmm moment_pro [if] [in] [weight],
　　      {equations(namelist) | nequations(#)}
　　      {parameters(namelist) | nparameters(#)}  [options]
　　      [program_options]
```

　　其中，`moment_prog` 是以矩条件为基础构造的<font color=blue> 矩估计表达式。</font>

　　各个选项具体说明如下：

- Model 选项
  - `derivative([reqname|#]/name=dexp_jk)` ：指定 `reqname （或 # ）` 对参数名的导数；可指定多于一次；
  - `twostep` ：使用两步 GMM 估计；
  - `onestep` ：使用一步 GMM 估计；
  - `igmm` ：使用迭代 GMM 估计；
  - `variables ( varlist )` ：在模型中指定变量；
  - `nocommonesample` ：不要限制所有方程的估计样本都是相同的。

- Instruments 选项
  - `instruments([reqlist:]varlist)[,noconstant])`： 是制定工具；可以被多次指定；
  - `xtinstruments([reqlist:]varlist,lags(#_1/#_2))` ：是制定面板类工具变量；可以被多次指定。

- Weight matrix 选项
  - `wmatrix(wmtype[,independent])` ：指定权重矩阵; `wmtype` 可以是`robust` ,`cluster` `clustvar` , `hac kernel [lags]` ，或者 `unadjusted`；
  - `center`： 计算权重矩阵时的中心矩；
  - `winitial(iwtype[, independent])`： 指定初始权重矩阵； `iwtype` 可以是`unadjested` , `identity` , `xt xtspec` ,或者 Stata 矩阵的名字。

- SE/Robust 选项
  - `vce(vcetype[,independent])`： 其中 `vcetype` 可以是 `robust` , `cluster` `clustvar` , `bootstrap` , `jackknife` , `hac kernel lags` ,或者 `unadjusted`
  - `quickderivatives`：采用VCE数值导数的另一种计算方法。

- Reporting 选项 
  - `level(#)` ：设置置信水平;默认是水平( 95 )  ；
  - `title(string)` ：将字符串显示为参数估计表上方的标题；
  - `title2(string)` ：显示字符串作为副标题；
  - `display_options` ：控制列与列格式、行间距、行宽、显示省略的变量、基单元格与空单元格，以及因子-变量标记。

- Optimization 选项  
  - `from(initial_values)` ：参数的指定初始值；
  - `igmmiterate(#)` ：指定迭代 GMM 估计的最大迭代次数；
  - `igmmeps` ：迭代的 GMM 参数收敛准则指定为 # ；默认为 igmmeps(1e-6)；
  - `igmmweps( # )` ：迭代的 GMM 权重矩阵收敛准则指定为 # ;默认是 igmmweps (1e-6)；
  - `optimization_options` ：控制优化过程；很少使用；
  - `coeflegend` ：显示图例而不是统计数据。




# 动态面板数据模型（FD-GMM与SYS-GMM）

　　动态面板数据模型，是指通过在静态面板数据模型中引入滞后被解释变量以反映动态滞后效应的模型。这种模型的特殊性在于被解释变量的动态滞后项与随机误差组成部分中的个体效应相关，从而造成估计的内生性。

　　也就是说在动态面板模型允许使用过去的可观测值，考虑了过去结果对当前结果的影响。而实际上许多经济学问题本质上都是动态的，其中一些经济模型表明，当前的行为依赖于过去的行为，例如就业模型和公司投资问题[^动态面板简介]。

[^动态面板简介]:[动态面板简介](https://www.jianshu.com/p/3767ee0ed284)

## 模型基本形式

### AR(1) 模型

$$
y_{i,t}=\delta y_{i,t-1}+x'_{i,t} \beta+\alpha_{i}+\varepsilon_{i,t} \tag{42}
$$

$$
i=1, \ldots, N \quad t=1, \ldots, T
$$

- 基本设定
  - $y_{i,t}$是一个$n_{i} \times 1$的向量,由时间t上的样本中每个空间单位的被解释变量的一个观测值，$\delta$为其在时间上的滞后值$y_{i,t-1}$的响应参数；
  - $x_{i,t}$是$n_{i}\times k$的外生解释变量矩阵，$\beta$为其响应参数向量；
  - $\alpha_{i}$是特定效应，且有$\alpha_{i} \sim (0,\sigma_{\alpha}^2)$；
  - $\epsilon_{i,t}$是服从 $i.i.d$ 分布的干扰项，且有$\epsilon_{i,t} \sim (0,\sigma_{\epsilon}^2)$

　　这里就特定效应类型将模型分为两大类。

### 固定效应模型(Fixed effect)

　　通过消去特定效应项$\alpha_{i}$得到
$$
y_{i,t}-\overline{y}_{i}=\delta(y_{i,t-1}-\overline{y}_{i.-1})+(x_{i,t}-\overline{x}_{i})\beta+(\epsilon_{i,t}-\overline{\epsilon}_{i})\tag{43}
$$

$$
\overline{y}_{i,-1}=\sum_{t=2}^{T}\frac{y_{i,t-1}}{T-1}
$$

　　但是此时$(y_{i,t-1}-\overline{y}_{i.-1})$与$(\epsilon_{i,t}-\overline{\epsilon}_{i})$相关，尽管是在$\epsilon_{i,t}$是序列不相关的的情况下。这是因为$y_{i,-1}$与$\overline{\epsilon}_{i}$相关，后一项的均值包含了$\epsilon_{i,t-1}$这一项，明显与$y_{i,t-1}$是相关的。这可以看出固定效应模型的估计是有偏的。

### 随机效应模型(Random effect )

　　若使用广义最小二乘法(GLS)，同理可知，$(y_{i,t-1}-\theta\overline{y}_{i.-1})$与$(\epsilon_{i,t}-\theta\overline{\epsilon}_{i})$是相关的。因此，可以看出，对于一个动态面板数据模型来说，若使用GLS估计方法，不管是固定效应模型还是随机效应模型，它的估计都是有偏且不一致连续的。且偏误$(bias)$的阶数是$\frac{1}{T}$,仅当$T\rightarrow \infty$时$bias\rightarrow0$。但是当 $T$ 很小，$N\rightarrow \infty$时可能会引起很大的偏误。

- **提出问题：为什么当 $T$固定，$N\rightarrow \infty$时会出现偏误和不一致连续的情况？**

  - 首先考虑没有外生向量的模型：
    $$
    y_{i,t}=\delta y_{i,t-1}+\alpha_{i}+\epsilon_{i,t} \quad \left| \delta\right|<1 \tag{44}
    $$

　　假设，对于向量 $y_{i,t}$ 我们在 $t=0,1,...,T$ 时有观测值，则固定效应模型的估计量为
    $$
    \hat{\delta_{FE}}=\frac{\sum_{i=1}^{N}\sum_{t=1}^{T}(y_{i,t}-\bar{y_{i}})(y_{i,t-1}-\bar{y_{i,-1}})}{\sum_{i=1}^{N}\sum_{t=1}^{T}(y_{i,t-1}-\bar{y_{i,-1}})^2 }\tag{45}
    $$

$$
\bar{y_{i,t}}=\frac{1}{T}\sum_{t=1}^{T}y_{i,t-1}
$$ 
$$
\bar{y_{i,-1}}=\frac{1}{T}\sum_{t=1}^{T}y_{i,t-1}
$$

　　将等式(44)代入等式(45)中，可以得到估计量的特征：
$$
\hat{\delta_{FE}}=\delta+\frac{\frac{1}{NT}\sum_{i=1}^{N}\sum_{t=1}^{T}(\epsilon_{i,t}-\bar{\epsilon_{i}})(y_{i,t-1}-\bar{y_{i,-1}})}{\frac{1}{NT}\sum_{i=1}^{N}\sum_{t=1}^{T}(y_{i,t-1}-\bar{y_{i,-1}})^2}\tag{46}
$$
　　等式(46)中，当 $T$固定，$N\rightarrow \infty$的情况下，FE模型的估计值有偏且不一致。因为等式(46)右边最后一项的期望不为零，且在$N\rightarrow \infty$的情况下不收敛到零。Nickell (1981) 和 Hsia (2003) 曾提出过：
$$
plim_{n\rightarrow \infty}\frac{1}{NT}\sum_{i=1}^{N}\sum_{t=1}^{T}(\epsilon_{i,t}-\bar{\epsilon_{i}})(y_{i,t-1}-\bar{y_{i,-1}})=-\frac{\delta_{\epsilon}^2}{T^2}\times\frac{(T-1)-T_{\delta+\delta^T}}{(1-\delta)^2}\neq0 \tag{47}
$$
　　因此，对于固定的 $T$，我们有不一致的估计量，不过这与$\alpha_{i}$无关，$\alpha_{i}$已经在估计过程过被去掉了。这里的问题是被解释变量的动态滞后项与随机误差组成部分中的个体效应相关，如在等式(43)与(46)我们所遇到的问题，即$y_{i,-1}$与$\overline{\epsilon}_{i}$相关。但当$T\rightarrow \infty$时，等式(47)收敛到零，此时当$T\rightarrow \infty$ 和$N\rightarrow \infty$时，$\delta_{FE}$的估计是一致的。

## 估计方法

###  IV

　　为了解决估计量不一致的问题，Anderson 和 Hsio (1981) 提出了**工具变量估计(IV)**。首先，我们考虑消去个体效应 $\alpha_{i}$，对此，做差分得：
$$
y_{i,t}-y_{i,t-1}=\delta(y_{i,t-1}-y_{i,t-2})+(\epsilon_{i,t}-\epsilon_{i,t-1}) \quad t=2,...,T\quad \tag{48}
$$

　　此处若使用最小二乘法(OSL)得到等式(48)的估计量是不一致的，尽管是在$T\rightarrow \infty$的情况下，这是因为$y_{i,t-1}$和$\epsilon_{i,t-1}$相关。

- 转换规范等式(48)给出一个IV估计的方法，例如，$y_{i,t-2}$与$(y_{i,t-1}-y_{i,t-2})$相关，但与$\epsilon_{i,t-1}$不相关，所以选取$y_{i,t-2}$作为工具变量，给出了$\delta$的一个IV估计：
  $$
  \hat{y_{IV}}=\frac{\sum_{i=1}^{N}\sum_{t=2}^{T}y_{i,t-2}(y_{i,t}-y_{i,t-1})}{\sum_{i=1}^{N}\sum_{t=2}^{T}y_{i,t-2}(y_{i,t-1}-y_{i,t-2})} \tag{49}
  $$


　　对应的关于等式(49)的一致性条件为
$$
plim_{N \rightarrow \infty}\frac{1}{N(T-1)}\sum_{i=1}^{N}\sum_{t=2}^{T}(\epsilon_{i,t}-\epsilon_{i,t-1})y_{i,t-2}=0 \quad \tag{50}
$$
　　$T\rightarrow \infty \ or \ N\rightarrow \infty \ or \ T\rightarrow \infty \ and \ N \rightarrow \infty$注意这里$(\epsilon_{i,t}-\epsilon_{i,t-1})$是MA(1)

　　Anderson 和 Hsio (1981)又给出了另一个IV估计的方案，这里选择将$(y_{i,t-2}-y_{i,t-3})$作为工具变量。
  $$
  \hat{y_{IV}}^{(2)}=\frac{\sum_{i=1}^{N}\sum_{t=3}^{T}(y_{i,t-2}-y_{i,t-3})(y_{i,t}-y_{i,t-1})}{\sum_{i=1}^{N}\sum_{t=3}^{T}(y_{i,t-2}-y_{i,t-3})(y_{i,t-1}-y_{i,t-2})} \tag{51}
  $$
　　同理，得到等式(51)的一致性条件为:
  $$
  plim_{N \rightarrow \infty}\frac{1}{N(T-2)}\sum_{i=1}^{N}\sum_{t=3}^{T}(\epsilon_{i,t}-\epsilon_{i,t-1})(y_{i,t-2}-y_{i,t-3})=0 \tag{52}
  $$

　　且只要$\epsilon_{i,t}$不是自相关的，等式(49)和(51)的一致性都得到了保障。

　　可以看出，等式(51)构建工具变量时比等式(49)多引入了一个滞后项，这导致缺失了一期的样本数据。这就又提出了一个问题，我们究竟是选择等式(49还是等式(51)的估计比较好？而矩估计(MM)法则不需要考虑这个问题，<font color=red >MM估计可以统一所有的估计量且消去样本容量减少的缺点。</font>

### GMM

　　可得等式(49)的矩条件为:
$$
plim_{N \rightarrow \infty}\frac{1}{N(T-1)}\sum_{i=1}^{N}\sum_{t=2}^{T}(\epsilon_{i,t}-\epsilon_{i,t-1})y_{i,t-2}=E[(\epsilon_{i,t}-\epsilon_{i,t-1})y_{i,t-2} ]=0 \tag{53}
$$
　　同理，等式(51)的矩条件为
$$
plim_{N \rightarrow \infty}\frac{1}{N(T-2)}\sum_{i=1}^{N}\sum_{t=3}^{T}(\epsilon_{i,t}-\epsilon_{i,t-1})(y_{i,t-2}-y_{i,t-3})\\=E[(\epsilon_{i,t}-\epsilon_{i,t-1})(y_{i,t-2}-y_{i,t-3})]=0 \tag{54}
$$
　　这两个IV估计值都在估计中附加了一个矩条件。但是，据我们所知，附加更多的矩条件则能增加估计值的效率。


　　据此，Arellano 和 Bond (1991) 提出可以通过开发附加矩来扩大工具的列表并且使工具的数量随着 t 变化。首先，固定T，这里考虑 T=4。

- t = 2 时，矩条件变为：$E[(\epsilon_{i,2}-\epsilon_{i,1})y_{i,0}]=0$
  这意味着变量$y_{i,0}$是有效的工具，因为它与$(y_{i,1}-y_{i,0})$高度相关而与$(\epsilon_{i,2}-\epsilon_{i,1})$不相关。   

- t = 3 时，同理可得，矩条件为：$E[(\epsilon_{i,3}-\epsilon_{i,2})y_{i,1}$同时也满足$E[(\epsilon_{i,2}-\epsilon_{i,1})y_{i,0}]=0$
　　其中，$ y_{i,1}$与$(y_{i,2}-y_{i,1})$相关，而与$(\epsilon_{i,3}-\epsilon_{i,2})$不相关。  
　　
- t = 4 时，我们将得到三组矩条件：$E[(\epsilon_{i,2}-\epsilon_{i,1})y_{i,0}]=0$；$E[(\epsilon_{i,3}-\epsilon_{i,2})y_{i,1}$；  $E[(\epsilon_{i,4}-\epsilon_{i, 3})y_{i,2}]=0$

　　一直继续这么添加矩条件之后，有效的工具集合变为$(y_{i0},y_{i1},y_{i2}...y_{i,T-2})$而所有的这些矩条件可以作为**广义矩估计(GMM)**的一个框架。对于一般的样本大小 T，所有差分后的误差项可排成一个向量：
$$
\Delta \varepsilon_{i}=\left( \begin{array}{c}{\varepsilon_{i 2}-\varepsilon_{i 1}} \\ {\cdots} \\ {\varepsilon_{i, T}-\varepsilon_{i, T-1}}\end{array}\right) \tag{55}
$$
　　由工具变量排成的矩阵为：
$$
Z_{i} =\left( \begin{array}{ccccccc}{y_{i0}} & {0} & {0} & {\ldots} & {0} & {\ldots} & {0}\\ {0} & {y_{i0}} & {y_{i1}} & {\ldots} & {0} & {\ldots} & {0} \\ {\vdots} & {\vdots} & {\vdots} & {\ldots} & {\vdots} & {\ddots} & {\vdots} \\ {0} & {0} & {0} & {\ldots} & {y_{i0}} & {\ldots} & {y_{i, T-2}} \end{array}\right) \tag{56}
$$
　　矩阵$Z_{i}$的每一行都包含了给定时段所有有效工具。因此，所有矩条件的集合可写为：
$$
E\left\{Z_{i}^{\prime} \Delta \varepsilon_{i}\right\}=0 \tag{57}
$$
　　为了得到GMM估计，将等式(57)改写成
$$
E\left\{Z_{i}^{\prime}\left(\Delta y_{i}-\gamma \Delta y_{i,-1}\right)\right\}=0 \tag{58}
$$

　　显然，矩条件的数量会增加未知参数的数量。 $\gamma$这里我们通过最小化由等式(58)所对应的条件表达的二次型来估计参数$\gamma$：
$$
\min _{\gamma}\left[\frac{1}{N} \sum_{i=1}^{N} Z_{i}^{\prime}\left(\Delta y_{i}-\gamma \Delta y_{i,-1}\right)\right]^{\prime} W_{N}\left[\frac{1}{N} \sum_{i=1}^{N} Z_{i}^{\prime}\left(\Delta y_{i}-\gamma \Delta y_{i,-1}\right)\right] \tag{59}
$$


　　其中$W_{i}$是定义的对称正定的权重矩阵。然后，通过对等式(59)关于$\gamma$求微分并求解$\gamma$得到GMM估计量：
$$
\gamma_{G \hat{M} M}=\left(\left(\sum_{i=1}^{N} \Delta y_{i,-1}^{\prime} Z_{i}\right) W_{N}\left(\sum_{i=1}^{N} Z_{i}^{\prime} \Delta y_{i,-1}\right)\right)^{-1}\\ 
\times\left(\sum_{i=1}^{N} \Delta y_{i,-1}^{\prime} Z_{i}\right) W_{N}\left(\sum_{i=1}^{N} Z_{i}^{\prime} \Delta y_{i}\right) \tag{60}
$$

　　MM估计并不强制要求$\varepsilon_{it}$关于个体与时间服从独立分布，但是需要注意的是，需要不存在自相关以保证矩条件有效。因此，在一个短面板（即T比较小），建议强制$\epsilon_{it}$不存在自相关，并结合同方差性假设。  　


　　Alvarez 和 Arellano (2003) 表示，通常，GMM估计在$T \rightarrow \infty , N \rightarrow \infty$的情况下仍然保持一致性。但是，对于$T \rightarrow \infty$的情况下，GMM估计和FE估计会很接近，这给我们估计方法提供了一个更具有吸引力的选择。

### 一阶差分GMM

　　Arellano和Bond ( 1991) 提出了一阶差分GMM (FD-GMM)估计方法，主要做法是用变量的水平滞后值作为其一阶差分项的工具变量。具体来说：

　　由我们上文所考虑的没有外生向量的模型(44)的水平方程$y_{i,t}=\delta y_{i,t-1}+\alpha_{i}+\varepsilon_{i,t}$，考虑它的差分方程
$$
\Delta y_{it}=\delta \Delta y_{i,t-1} + \Delta \varepsilon_{it} \tag{61}
$$
　　因为$\Delta y_{i,t-1}$相关联，所以将$y_{i,t-2}$作为$\Delta y_{i,t-1}$的工具变量。这种估计方法就是FD-GMM。<font color=blue> 但是, Blundell和Bond (1998)曾指出,一阶差分GMM估计方法容易受到弱工具变量的影响而得到有偏的估计结果。</font>即由模型(44)的水平方程可得
$$
\Delta y_{i,t-1}=(\delta-1)y_{i,t-2}+\alpha_{i}+\varepsilon_{i,t-1}\tag{62}
$$
　　当$\delta$接近1的时候，工具变量和外生变量的关系就会变的很弱，这就会产生“弱工具变量问题”。 为了克服弱工具变量的影响, Arellano和Bover (1995) 以及Blundell和Bond (1998)提出了另外一种更加有效的方法,即系统GMM (SYS-GMM)估计方法。其具体做法是将水平方程和差分方程结合起来进行估计,在这种估计方法中,滞后水平作为一阶差分的工具变量,而一阶差分又作为水平变量的工具变量。具体来说：在上述FD-GMM估计中，可以看作是应用了矩条件$E(\Delta \varepsilon_{it}y_{i,t-2}=0)$，但是却有个矩条件被忽略了， 即：
$$
E\left(\Delta y_{i, t-1}\left(\alpha_{i}+\varepsilon_{i t}\right)\right)=E\left(\Delta y_{i, t-1}\left(y_{i t}-\delta y_{i, t-1}\right)\right)=0\tag{63}
$$

　　 而SYS-GMM则是考虑到了这一点，利用了更多的有效信息，使得估计不受$\delta$接近1时的影响。 

## 一些注意事项

　　 动态面板数据模型，是指通过在静态面板数据模型中引入滞后被解释变量以反映动态滞后效应的模型。<font color=blue> 这种模型的特殊性在于被解释变量的动态滞后项与随机误差组成部分中的个体效应相关，从而造成估计的内生性。</font>

　　也就是说在动态面板模型允许使用过去的可观测值，考虑了过去结果对当前结果的影响。而实际上许多经济学问题本质上都是动态的，其中一些经济模型表明，当前的行为依赖于过去的行为，例如**就业模型**和**公司投资问题**。

### 模型的一些假设

- 1、动态。模型中包含了因变量的滞后项；
- 2、有个体的固定效应；
- 3、可以有一些自变量是内生的；
- 4、除了固定效应之外的误差项$\varepsilon_{i,t}$可以异方差，可以序列相关；
- 5、不同个体之间的误差项$\varepsilon_{i,t}$和$\varepsilon_{j,t}$不会相关。
- 6、可以有前定的（Predetermined）但不是完全外生的变量。
- 7、“大N，小T”，即个体数量要足够多，但时间不用太长。如果时间足够长的话，动态面板误差不会太大，用固定效应即可。

　　从上述要求可以看出，GMM方法特别适合宏观的面板数据分析，因为宏观变量中，很难找出绝对外生的变量，变量之间多少会互相影响。而GMM方法可以“有一些自变量是内生的”，这可能也是GMM方法在文献中这么常用的原因。此前已经说过，不能用传统的OLS方法或者固定效应模型进行动态面板数据的分析，那样会得到有偏的估计量。先要对数据进行一定的变换，然后根据不同的矩条件设定开展矩估计。其中数据变换有两种方法，矩条件的设定也有两种方法。  

### 数据的变换方法

　　**一阶差分还是垂直离差。**为了消除动态面板数据中的固定效应，通常用的有两种方法：一阶差分(first difference)和垂直离差(orthogonal deviations)。一阶差分之前已经介绍过了，这种方法是difference GMM 中默认的方法。缺点是如果数据中有缺失值，那么最终的估计会缺失很多样本，原始数据缺一行往往会导致差分后的数据缺两行。一种替代的方案是用垂直离差（xtabond2 命令中用 orthogonal 选项实现），每个变量减去该变量未来所有观测值的平均值，即：  
　　
$$
w_{i, t+1}^{\perp} \equiv c_{i t}\left(w_{i, t}-\frac{1}{T_{i t}} \sum_{s>t} w_{i s}\right) \tag{64}
$$
　　式子中（64），$c_{i t}=\sqrt{T_{i t} /\left(T_{i t}+1\right)}$为调整权重变量， $T_{i,t}$是从$t$期开始以后观测值的数量。<font color=blue >对于非平衡面板，和数据有缺失的面板，这种方法避免了因缺失数据带来的样本损失，因为调整的时候只是把未来的平均值减去，样本数不会因缺失未来个别观测值而受损。然而，对于平衡面板数据，一阶差分和垂直离差估计出来的结果会完全一样。</font>


### 模型的选择

　　**Different GMM还是 System GMM**。令数据变换之后的回归方程变为:  
　　
$$
Y_{i, t}^{*}=\alpha Y_{i, t-1}^{*}+\beta X_{i t}^{*}+\varepsilon_{i t}\tag{65}
$$
　　这种变换可以是一阶差分，也可以是垂直离差。Different GMM的逻辑是，如果是垂直离差变换，用 

$Y_{i, t-2}$作为 $Y_{i, t-1}^{*}$的工具变量；如果是一阶差分变换，用$\Delta Y_{i, t-2}$作为 $Y_{i, t-1}^{*}$的工具变量，此时 $Y_{i, t-1}^{*}=\Delta Y_{i, t-2}$。$X_{i, t}^{*}$对应的工具变量也类似，如果是垂直离差，就用滞后一阶的，如果是差分就用滞后一阶的差分作为工具变量。在实现的时候，为了提高估计的有效性，通常还会加入更高阶的滞后项（滞后差分）作为工具变量。这些变量的加入利用了更多的信息，然而也会带来麻烦，让工具变量的数量随T平方成比例增加。为了控制工具变量的数量，一个选择就是采用collapse选项把这些工具变量变成一列。

　　如果因变量的变化过程接近随机游走，那么Difference GMM的估计量会有较大偏差。

　　system GMM的方法和Different GMM完全不同，它不需要对自变量和因变量进行数据变换。它假定工具变量的差分，即 $\Delta w_{i t}=w_{i t}-w_{i, t-1}$，应该外生于固定效应： $E\left(\Delta w_{i t}u_{i}\right)=0$。如果 $w$是内生的，$\Delta w_{i t-1}$就可以作为工具变量，更高阶的差分也可以做工具变量。如果$w$是前定的但不是完全外生的， $\Delta w_{i t}$可以作为工具变量，更高阶的差分也可以做工具变量。当然，更高阶差分加入后，还是会增加工具变量数量，需要在具体计算时想办法控制。

### 使用GMM方法的注意事项

　　可以尝试先做（2）式的OLS，再做（3）式的固定效应。当然这两个估计都是有偏误的，然而这两个估计的系数应该是真实系数的上限和下限，可以给最后的 GMM 估计限定参考范围。

　　大 N小T，如果N太小了，则估计出来的标准差可能不太靠谱。实际上如果用省际面板去做的话，不满足大N小T个条件，但中文文献中充斥着这样的研究。如果样本的 N较小，但还可以接受（比如 N=70），然而又想用此方法，那么加上small选项。

　　解释变量中，放入时间虚拟变量。比如，数据有 10 年，则放入 9 个虚拟变量。加入后，可以让误差项 $\varepsilon_{i,t}$和$\varepsilon_{j,t}$不会相关这个条件更容易满足。

　　如果数据中间有间隙，尽量利用垂直离差（对于每个变量，包括自变量和因变量， 减去它未来值的平均值，就是加上 orthogonal 选项，见 Roodman（2009）），这会减少样本量的损失。因为数据中间缺一行，一阶差分（$w_{i,t}-w_{i,t-1}$）后就会缺两行数据。但对平衡面板数据，两种数据变换方法结果一样。

　　通常，每个自变量都要出现两次（除了系统外的工具变量）。先作为自变量出现在在xtabond2 命令中逗号的左边，再以某种形式作为工具变量出现在逗号右边。如果变量是完全外生的，那么放到 ivstyle(w)（表示直接作为工具变量）；如果是前定的，但不是完全外生的，则放到 gmmstyle(w)（表示从滞后一期开始都作为工具变量）;如果是内生的，则放到 gmmstyle(L.w)（表示从滞后两期开始都作为工具变量）。

　　报告工具变量的数量。如果按照上一条的做法，工具变量的数量会很多。这样会导致overidentification test不准确，【一个标志就是 Hansen 统计量的 p 值变为 1，Hansen test的 p 值在（0.1,0.25）之外都要小心，太小表明拒绝工具变量有效的假设，太大表明选的工具变量太多，hansen检验变弱了】。通常，需要限制工具变量数量，可以用collapse选项，也可以用 laglimits()选项。习惯做法是，选择不同数量的工具变量以显示估计系数的稳健性。工具变量数量的上限就是模型中个体的数量（也就是 N），超出此上限，xtabond2 命令会报警。

　　使用 system GMM 的时候要注意，能使用该模型的前提是，工具变量的变化$w_{i,t}-w_{i,t-1}$要和固定效应垂直。因此数据应该在稳态附近，否则这些变量的变化就会和固定效应关系比较大，从而不满足 system GMM 适用的条件。

　　由于 GMM 方法有很多设定选项，在报告结果时，报告你的选项。System GMM 还是Difference GMM；是用垂直离差还是一阶差分；选用什么工具变量，滞后几期；选择什么样的 robust 标准差，等等。



　

## GMM在动态面板估计中的案例

　　动态面板GMM常用的Stata命令：

- `xtabond`命令实现了 Arellano 和 Bond Roodman在1991年所提出的一阶差分矩估计法（FD-GMM），此时它的矩条件是将因变量的滞后和外生变量的一阶差分作为一阶差分方程的工具。  

- `xtdpdsys`实现了Arellano、Bover/Blundell 和 Bond在1998年提出的系统 GMM 估计（SYS-GMM） ，它使用了`xtabond`的矩条件，同时又将因变量滞后第一差分作为水平方程的工具。  

- `xtdpd`则是一种更加灵活的替代方法，它可以用比`xtabond`和`xtdpdsys`更复杂的结构来拟合在特殊误差和预定变量中具有低阶移动平均关联的模型。  

- `estat bond`允许您在一阶差分残差中测试序列相关性，并测试过度识别限。  

- `estat overid`允许您在估计后进行过度识别检验。

### FD-GMM

> 　　例子：  
> 　　基于Layard和Nickell(1986)的工作，Arellano和Bond(1991)将劳动力需求的动态模型拟合到位于英国的一个具有不平衡面板的公司上。首先，我们根据 工资(wages)、资本存量(capital stock)、行业产出(industry output)、年度虚拟变量(year dummies) 以及 一个时间趋势(a time trend )对就业率(employment) 进行建模，其中包括就业，工资和资本存量的滞后。我们将使用xtabond命令



- 我们可以使用`xtabond`命令来实现FD-GMM估计，这里我们使用数据`abdata`

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
use E:\Mirror\StataLearn\StataData\abdata.dta
xtabond n L(0/2).(w k) yr1980-yr1984 year, vce(robust)
```




　　 `GMM`命令与`xtabond`命令的比较。
 
 
 ```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
use E:\Mirror\StataLearn\StataData\abdata.dta,clear
xtabond n L(0/1).w L(0/1).k, lags(1) noconstant vce(robust)

```

　　 也可以用GMM 的形式估计动态面板，表示为：
　　 
 ```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
use E:\Mirror\StataLearn\StataData\abdata.dta,clear
gmm (D.n - {rho}*LD.n - {xb:D.w LD.w D.k LD.k}),  ///
    xtinstruments(n, lags(2/.)) ///
    instruments(D.w LD.w D.k LD.k, noconstant) ///
    deriv(/rho = -1*LD.n) deriv(/xb = -1) winitial(xt D) onestep
```　　 
　　由于我们的回归模型中包含一个n的滞后，`xtabond`使用滞后2期和back作为工具。外生变量的差分也可以作为工具。接下来，我们使用`xtdpdsys`来重新定义模型。   　　　

### SYS-GMM  


- 下面用`xtdpdsys`命令来实现SYS-GMM估计


 ```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
use E:\Mirror\StataLearn\StataData\abdata.dta,clear
xtdpdsys n L(0/2).(w k) yr1980-yr1984 year, vce(robust)
```　

　　 比较这两个命令输出的页脚说明了这两个估计器之间的关键区别。`xtdpdsys`将n的滞后差也作为工具纳入水平方程，而`xtabond`没有。`xtdpdsys`的工具变量变多了，但是模型的标准误降低了。　　　　


　　 这些GMM估计量的矩条件只有在特征误差不存在序列相关性的情况下才有效。由于白噪声的第一个差异必然是自相关的，我们只需要关注第二个和更高的自相关。我们可以使用`estat abond`测试自相关:　　　


>  `xtdpd`则是一种更加灵活的替代方法，它可以用比`xtabond`和`xtdpdsys`更复杂的结构来拟合在特殊误差和预定变量中具有低阶移动平均关联的模型。

### 假设检验

#### 序列相关检验

　　 可以看出 Arellano–Bond估计工具变量的设定的关键点在于
$$
E\left(\Delta y_{i(t-j)} \Delta \varepsilon_{i t}\right)=0 \quad j \geq 2\tag{66}
$$   
　　 我们可以在 Stata 中使用`estat abond`命令来测试这些条件。
　　 从本质上来说，一般未观测到的的差分项$\Delta y_{it}$应与其因变量的第二期滞后$y_{i,t-2}$和之后的滞后项都无关。如果不是这样，我们又回到了一开始的问题，内生性。所以我们主要关心的是有没有2阶或者更高阶的序列相关性。 
　　 下面我们用`estat bond`命令来测试我们上述的例子：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta,clear
qui xtdpdsys n L(0/2).(w k) yr1980-yr1984 year, vce(robust)
*序列相关检验
estat abond, artests(4)
```

　　可以看到的是，我们可以拒绝一阶序列相关的原假设，但是不能拒绝2、3、4阶序列相关的原假设。所以原模型是合理的。

#### 过度识别检验（estat overid）

　　检验工具变量是否是与干扰项相关，也就是工具变量是否为外生变量。
　　

　　原假设是：所有工具变量都是外生。其中包含 `hansen` 检验和` sargan` 检验，可以用 Stata 中的`xtabond2`命令实现。

# 关于动态面板模型估计的 Stata 命令


## Stata实操陷阱：动态面板数据模型

### 问题背景

　　关于动态面板数据模型 (dynamic panel data，DPD)，我们常常会遇到如下问题[^Stata实操陷阱：动态面板数据模型]：

[^Stata实操陷阱：动态面板数据模型]:[Stata实操陷阱：动态面板数据模型](https://www.lianxh.cn/news/cc6c5ea80d70c.html)

- 如何在一阶差分 GMM 和系统 GMM 间选择；  
- 该用 Stata 哪个命令对模型进行估计；  
- 当解释变量中含有内生变量时，应该如何对模型进行估计；  
- 干扰项序列相关检验无法通过怎么办；  
- 过度识别检验无法通过怎么办；   
- 大 T 小 N 型面板能否用 GMM 进行估计。   

　　接下来，本文将对上述问题提出对应的解决方案。



### FD-GMM 还是 SYS-GMM

　　需要强调的是，无论一阶差分GMM (FD-GMM)还是系统 GMM (SYS-GMM)，模型设定是不受影响的，并且二者仅在计量估计方法上不一样，即矩条件不同。SYS-GMM 使用的矩条件多，利用的信息也多，估计也更有效率，但其受到的限制也多，如假定被解释变量的一阶差分项与个体效应变量不相关。更多细节参考IV-GMM[^IV-GMM]。
　　
[^IV-GMM]:[IV-GMM](https://www.lianxh.cn/blogs/38.html)

　　**那么，在估计模型时该选择哪种估计方法呢？**

　　Bond (2002) 认为当被解释变量的一阶滞后项系数 不是很大时，如 ，FD-GMM 估计结果较好，而当 时，SYS-GMM 较好。

　　此外，若对性别、户口、行业等不随时间变化变量感兴趣，则必须使用 SYS-GMM 估计。  


### 关于动态面板模型估计的 Stata 命令

　　动态面板数据模型的估计主要有4个 Stata 命令，其中官方命令为 `xtabond`、`xtdpdsys`、`xtdpd`，非官方命令为 `xtabond2`，具体如下：

- `xtabond` 用于 FD-GMM 估计；
- `xtdpdsys` 用于 SYS-GMM 估计；
- `xtdpd` 用于 FD-GMM 和 SYS-GMM 估计；
- `xtabond2` 用于 FD-GMM 和 SYS-GMM 估计。

　　其中，`xtabond2` 可以提供由异方差调整后的 Hansen 统计量。



#### 动态面板模型案例

　　接下来，我们将使用 Arellano and Bond (1991)在研究企业雇佣员工数量的影响因素时的数据 `abdata.dta`，来说明 GMM 相关命令的应用。其中，模型设定如下：

$$
n_{i t}=\alpha_{1} n_{i(t-1)}+\alpha_{2} n_{i(t-2)}+\beta^{\prime}(L) x_{i t}+\lambda_{t} \dashv \eta_{i}+v_{i t}  \tag{67}
$$

- $n_{i t}$企业$i$在第$t$年末雇佣员工数量的对数值；  

- $n_{i t-1}$企业$i$在第$t-1$年末雇佣员工数量的对数值；   

- $(L) x_{i t}$表示解释变量$x$及其滞后项，具体包括：
  - $w_{i t}$和$w_{i t-1}$ (即企业$i$在第$t$和$t-1$年实际工资的对数)；
  - $k_{i t}$、$k_{i t-1}$和$k_{i t-2}$(即企业$i$在第$t$、$t-1$和$t-2$ 年资本存量的对数)；
  - $ys_{i t}$、$ys_{i t-1}$和$ys_{i t-2}$(即企业$i$在第$t$、$t-1$和$t-2$ 年总产出的对数)；  
  
-  $\lambda{t}$为年份虚拟变量，其含义为总需求每年受到的外部冲击，也可表示为`i.yr1979-yr1984`。


#### FD-GMM 的实现

##### 采用xtabond命令进行FD-GMM估计   

　　`xtabond` 命令语法格式:

```
xtabond depvar [indepvars] [if] [in] [,options]
```

　　主要选项的含义为：

- `depvar`：被解释变量；  
- `indepvars`：严格外生的解释变量；  
- `noconstant`：无常数项；   
- `lags(p)`：表示使用被解释变量 p 阶滞后值作为解释变量，默认一阶滞后 `lags(1)`；   
- `maxldep(q)`：表示最多使用 q阶被解释变量的滞后值作为工具变量，默认使用所有可能的滞后值；    
- `endogenous()`：内生解释变量，可使用多次；  
- `twostep`：两阶段估计，可修正 Sargan 统计量；    
- `inst()`：其他的工具变量 (除解释变量滞后项以外)；    
- `vce()`：默认为 `vce(gmm)`，计算得到普通 GMM 标准误，`vce(robust)` 为异方差稳健稳健标准误。   

　　`xtabond` 估计命令：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
*数据下载地址
*https://gitee.com/arlionn/data/blob/master/data01/abdata.dta
*use abdata, clear   // 调用数据
*-or
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984,  ///
	  lags(2) twostep vce(robust)   // L(0/1).w 表示 w 的当期值与一阶滞后
```

##### 采用xtdpd命令进行FD-GMM估计       

　　`xtdpd` 命令语法格式:

```
 xtdpd depvar [indepvars] [if] [in] , dgmmiv(varlist [...]) [options]
```

　　主要选项的含义为：

- `dgmmiv(varlist [, lagrange(flag [llag])])`：指定内生的被解释变量或者内生解释变量，以及其滞后项作为差分方程的 GMM 式工具变量，默认 `flag` 为 2，比如 `dgmmiv(y , lagrange(2 4))` 将变量的 **y** 的 2-4 阶滞后项作为工具变量，`dgmmiv(y)` 将变量的 **y** 的 2-n 阶滞后项作为工具变量；    
- `lgmmiv(varlist [, lag(#)])`：将被解释变量或者内生解释变量的一阶差分的 # 阶滞后作为水平方程的 GMM 型工具变量，默认阶数为 1；    
- `iv(varlist [, nodifference])`：指定外生变量的一阶差分项作为差分方程的标准型的工具变量，加上 `nodifference` 后作为水平方程的标准型的工具变量；    
- `div(varlist)`：为差分方程设定额外的标准型工具变量；    
- `liv(varlist)`：为水平方程设定额外的标准型工具变量；     
- `twostep` 和 `vce()` 含义与 `xtabond` 命令相同。     

　　`xtdpd` 估计命令：    

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtdpd n l(1/2).n L(0/1).w L(0/2).(k ys) yr1980-yr1984, ///
      dgmmiv(n) div(L(0/1).w L(0/2).(k ys)) ///
      div(yr1980-yr1984) twostep vce(robust)
```

#####　采用xtabond2命令进行FD-GMM估计     

　　`xtabond2` 命令语法格式：

```
xtabond2 depvar varlist [if] [in]  ///
   [, gmm(varlist [, laglimits(a b) collapse)])  ///
      iv(varlist [, equation()])   ///
      nolevel nocons twostep robust
   ]
```

　　主要选项的含义为：　　　

- `gmm()`：指定内生的被解释变量或者内生解释变量，以及其滞后项作为 GMM 式工具变量，`laglimits(a b)` 限定工具变量滞后的阶数，默认为1到n，`collapse` 系统自动删减工具变量地个数；　　　
- `iv(varlist [, equation()])`：指定 IV 式工具变量，`equation({diff | level | both})` 对差分方程和水平方程进行选择；　　
- `nolevel`：表示不估计水平方程，进行FD-GMM 估计，默认为SYS-GMM估计；
- `robust`：异方差稳健标准误。　　

　　`xtabond2` 估计命令：　　　

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
*ssc install xtabond2, replace // xtabond2 是外部命令需要下载
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtabond2 n l(1/2).n l(0/1).w l(0/2).(k ys)  yr1980-yr1984,      ///
         gmm(l.n) iv(l(0/1).w l(0/2).(k ys))  ///
         iv(yr1980-yr1984) ///
         nolevel twostep robust
```


#### SYS-GMM的实现      

##### 采用xtdpdsys命令进行SYS-GMM估计   

　　`xtdpdsys` 命令语法格式：

```
xtdpdsys depvar [indepvars] [if] [in] [,options]
```

　　主要选项的含义为：

- `noconstant`：无常数项；   
- `lags(p)`：表示使用被解释变量 p 阶滞后值作为解释变量，默认一阶滞后；    
- `maxldep(q)`：表示最多使用 q    阶被解释变量的滞后值作为工具变量,，默认使用所有可能的滞后值；    
- `pre()`：指定前定变量；    
- `endogenous ()`：指定内生解释变量，可使用多次；    
- `twostep` 和 `vce()`：与 `xtabond` 命令相同。    

　　`xtdpdsys` 估计命令：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtdpdsys n L(0/1).w L(0/2).(k ys) yr1980-yr1984, ///
         lags(2) twostep vce(robust)
```


##### 采用xtdpd命令进行SYS-GMM估计    

　　`xtdpd` 估计命令：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtdpd n L(1/2).n L(0/1).w L(0/2).(k ys) yr1980-yr1984, ///
      dgmmiv(n) lgmmiv(n) div(L(0/1).w L(0/2).(k ys))       ///
      div(yr1980-yr1984) twostep vce(robust)
est store Sysxtdpd
```

##### 采用xtabond2命令进行SYS-GMM估计    

　　`xtabond2` 估计命令：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtabond2 n l(1/2).n l(0/1).w l(0/2).(k ys) yr1980-yr1984, ///
         gmm(l.n) iv(l(0/1).w l(0/2).(k ys), eq(diff))     ///
         iv(yr1980-yr1984,eq(diff)) twostep robust
```



##### 模型估计结果比较           

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
*数据下载地址
*https://gitee.com/arlionn/data/blob/master/data01/abdata.dta
*use abdata, clear   // 调用数据
*-or
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
*---------FD-GMM
*xtabond 估计命令：
xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984,  ///
	  lags(2) twostep vce(robust)   // L(0/1).w 表示 w 的当期值与一阶滞后
est store Fdxtabond

*xtdpd 估计命令：
xtdpd n l(1/2).n L(0/1).w L(0/2).(k ys) yr1980-yr1984, ///
      dgmmiv(n) div(L(0/1).w L(0/2).(k ys)) ///
      div(yr1980-yr1984) twostep vce(robust)
est store Fdxtdpd  

*xtabond2 估计命令：

xtabond2 n l(1/2).n l(0/1).w l(0/2).(k ys)  yr1980-yr1984,      ///
         gmm(l.n) iv(l(0/1).w l(0/2).(k ys))  ///
         iv(yr1980-yr1984) ///
         nolevel twostep robust
est store Fdxtabond2
*---------SYS-GMM
*xtabond2 估计命令
xtdpdsys n L(0/1).w L(0/2).(k ys) yr1980-yr1984, ///
         lags(2) twostep vce(robust)
est store Sysxtdpdsys 

*xtdpd 估计命令：
xtdpd n L(1/2).n L(0/1).w L(0/2).(k ys) yr1980-yr1984, ///
      dgmmiv(n) lgmmiv(n) div(L(0/1).w L(0/2).(k ys))       ///
      div(yr1980-yr1984) twostep vce(robust)
est store Sysxtdpd

*xtabond2 估计命令：
xtabond2 n l(1/2).n l(0/1).w l(0/2).(k ys) yr1980-yr1984, ///
         gmm(l.n) iv(l(0/1).w l(0/2).(k ys), eq(diff))     ///
         iv(yr1980-yr1984,eq(diff)) twostep robust
est store Sysxtabond2

*结果汇总
local mm "Fdxtabond Fdxtdpd Fdxtabond2 Sysxtdpdsys Sysxtdpd Sysxtabond2"
esttab `mm', mtitle(`mm') compress star(* 0.1 ** 0.05 *** 0.01) b(%10.3f) nogap
```



　　由上表可以看出，在 FD-GMM 估计中，雇佣员工数量对数的一阶滞后项的系数在 0.6 左右，而在 SYS-GMM 估计中的系数为 0.9 左右，同时，SYS-GMM 估计结果整体偏高，并且各个系数显著性水平也更高。

　　对于 FD-GMM 估计，三种命令估计的结果相同，因此在做 FD-GMM 时，选择三者之中任意命令对结果没有影响，而对于 SYS-GMM 估计，`xtdpdsys` 和 `xtdpd` 的估计结果一致，而 `xtabond2` 估计结果与前面两个命令有差异。


### 解释变量中含有内生变量    

　　考虑如下模型：

$$
y_{i t}=a_{0} y_{i t-1}+a_{1} x_{i t}+a_{2} k_{i t}+u_{i}+v_{i t-1} \tag{68}
$$

　　其中，$y_{i t-1}$是一个典型的内生变量，这里用$L \cdot(2 / .) y_{i t}$作为D. $y_{i t-1}$的工具变量，假设$k_{i t}$为内生解释变量，使用其二阶及更高阶的滞后项$L \cdot(2 / .) k_{i t}$作为工具变量 。

　　具体命令使用：

- `xtabond`: `endogenous()` 选项来设定内生解释变量，在本例中为 `endogenous(k)`，如果限定使用$k_{i t}$ 工具变量的个数，比如只使用二阶和三阶滞后项，则可以设定为 `endogenous(k, lag(0 2))`; 如果内生变量为$k_{i t}$的滞后一期，则可以设定为 `endogenous(k, lag(1 2))`，此时工具变量为滞后项$k_{i t-1}$的二、三阶滞后项
- `xtdpd`：`dgmmiv()` 和 `lgmmiv()`选项来设定内生变量 (包括被解释变量和解释变量)，当使用 FD-GMM 估计时，设定为 `dgmmiv(y k)`，而使用SYS-GMM估计时，则设定为`dgmmiv(y k) lgmmiv(y k)`
- `xtabond2`：`gmm()` 选项来设定内生变量 (包括被解释变量和解释变量)，对于内生被解释变量设定为 `gmm(l.y)` 或者 `gmm(y, lag(2 .))` ，为将解释变量的二阶及所有高阶滞后项作为工具变量；对于内生解释变量设定为`gmm(k)` ，其含义是将解释变量的一阶及所有高阶滞后项作为工具变量，若设定成`gmm(k, lag(2 3))`则为将解释变量的二阶和三阶滞后项作为工具变量
- `xtdpdsys`：`endogenous()` 选项来设定内生解释变量，设定为`endogenous(k)` ，表示将内生解释变量 k 的二阶及所有高阶滞后项作为工具变量；设定为`endogenous(k lag(0, 2))` ，表示将内生解释变量 k 的二阶和三阶滞后项作为工具变量，其中 0 为变量 k 的当期值作为内生变量，2 表示内生变量 k 的滞后 2 阶和 3 阶项作为工具变量； 若设定为 `endogenous(k, lag(1, 3))`表示将内生解释变量 L.k ( k 的一阶滞后项) 的二、三、四阶滞后项 (即 L(2/4).L.k) 作为工具变量。  


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
*以abdata.dta数据为例，假设资本存量 k 为内生变量，k 的设定如下

xtabond n L(0/1).w L(0/2).ys yr1980-yr1984, lags(2) endogenous(k) twostep vce(robust)

xtabond n L(0/1).w L(0/2).ys yr1980-yr1984, lags(2) endogenous(k, lag(0, 2)) twostep vce(robust)
// 限定内生解释变量工具变量的滞后阶数

xtabond n L(0/1).w L(0/2).ys yr1980-yr1984, lags(2) endogenous(k, lag(1, 2)) twostep vce(robust)
// 设定滞后项的内生解释变量

xtdpd n L(1/2).n L(0/1).w L(0/2).ys k yr1980-yr1984, dgmmiv(n k) div(L(0/1).w L(0/2).ys) ///
    div(yr1980-yr1984) twostep vce(robust) // FD-GMM 估计

xtdpd n L(1/2).n L(0/1).w L(0/2).ys k yr1980-yr1984, dgmmiv(n  k) lgmmiv(n  k) ///
            div(year yr1979-yr1984) nocons hascons vce(robust) // SYS-GMM 估计

xtabond2 n l(1/2).n l(0/1).w l(0/2).ys k yr1980-yr1984, ///
    gmm(l.n k) iv(l(0/1).w l(0/2).ys) iv(yr1980-yr1984) nolevel twostep robust

xtabond2 n l(1/2).n l(0/1).w l(0/2).ys k yr1980-yr1984, ///
    gmm(l.n) gmm(k, lag(2 3)) iv(l(0/1).w l(0/2).ys) iv(yr1980-yr1984) nolevel twostep robust
// 限定内生解释变量工具变量的滞后阶数

xtdpdsys n L(0/1).w L(0/2).ys k yr1980-yr1984, ///
    lags(2) endog(k) twostep vce(robust) // SYS-GMM 估计

xtdpdsys n L(0/1).w L(0/2).ys k yr1980-yr1984, ///
    lags(2) endog(k, lag(0, 2)) twostep vce(robust) // 限定内生解释变量工具变量的滞后阶数

xtdpdsys n L(0/1).w L(0/2).ys k yr1980-yr1984, ///
    lags(2) endogenous(k, lag(1, 3)) twostep vce(robust) // 设定滞后项的内生解释变量
```





### 干扰项序列相关检验无法通过  

　　Arellano and Bond (1991) 估计工具变量的设定关键点：

$$
E\left(\Delta y_{i(t-j)} \Delta \varepsilon_{i t}\right)=0 \quad j \geq 2 \tag{69}
$$

　　换言之，FD-GMM 和 SYS-GMM 成立的前提是扰动项 $\epsilon_{i t}$ 不存在序列相关，否则就会导致内生性问题。因此，需要对扰动项序列相关进行检验，具体如下：

　　原假设：扰动项不存在序列相关；   

- “扰动项的一阶差分” 存在自相关：

- 扰动项的差分不存在二阶或更高的自相关：

　　故可通过检验扰动项的差分是否存在二阶 (或更高阶) 的自相关来检验原假设。

　　Stata 命令为 `estat abond`。

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984, lags(2) twostep vce(robust)
estat abond
```



　　可以看出，在 5% 的显著性水平下，扰动项的差分存在一阶自相关，但不存在二阶自相关，故不拒绝原假设。

　　如果无法通过序列相关检验，主要原因可能是干扰项中包含了一些序列相关特征较为明显的变量。此时，我们可以通过增加解释变量，以使干扰项变得更「干净」。具体设定如下：

- 加入时间虚拟变量；
- 加入部分解释变量的滞后项 (要有一定的理论依据)；
- 加入被解释变量的滞后项，可以通过 `xtabond` 命令的 `lag(#)` 选项来设定。

　　需要特别说明的是，序列相关检验和过度识别检验往往要同步进行。因为，如果选择的工具变量不妥 (表现为过度识别检验无法通过)，序列相关检验也就没有了根基。


### 过度识别检验无法通过   

　　在工具变量大于内生变量个数时，需要进行过度识别检验。基本原理是检验工具变量是否是与干扰项相关，即工具变量是否为外生变量。具体如下：

　　原假设：所有工具变量都是外生；

　　方法：在 `xtabond` 命令以后，使用 `estat sargan` 命令。

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
quietly xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984, lags(2)  // 不使用 VCE(robust)
estat sargan  // 过度识别检验
```




　　可以看出，该结果拒绝了原假设，即认为存在工具变量和干扰项是相关。 但是 Arellano and Bond (1991) 指出，当干扰项存在异方差时， Sargan检验倾向于过度拒绝原假设，因此得到的结论并不可信。建议采用两阶段估计，再执行 Sargan 检验比较稳妥。


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
quietly xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984, twostep lags(2)   // 不使用 VCE(robust)
estat sargan  // 使用两阶段估计后的过度识别检验
```




　　可以看出，结果没有拒绝原假设，即工具变量与扰动项不相关。

　　实际上，Sargan 检验是联合检验：(1) 模型的设定正确 (2) 工具变量合理。因此，若拒绝原假设，则说明前面两个假设至少有一个存在问题。此时，应该先考虑模型的设定是否有问题，进而分析工具变量的设定是否合理。

　　关于工具变量，通常使用$y_{t-s}(s \geq 2)$作为$\Delta y_{i t-1}$的工具变量，但当$T$ 较大时，就会有很多个工具变量。显然，随着$s$的增加，$\rho_{s}=\operatorname{corr}\left(\Delta y_{i t-1}, y_{t-s}\right)$会越来越小。一般而言，当$s>6$以后，对应的工具变量很可能是弱工具变量，即$y_{t-7}$与$\Delta y_{i t-1}$的相关性很低。

　　通过减少工具变量的使用，一定程度上可以避免弱工具变量问题。在 `xtabond` 命令中，可以使用 `maxldep(#)` 来限制工具变量的最大滞后阶数，进而达到限制工具变量总数的目的。例如，`xtabond y x, maxldep(5)` 意味着最多只用五个滞后项 (注意：不是五阶滞后)，即用$y_{t-2}, \cdots y_{t-6}$作为的工具变量。

　　未使用 `maxldep()` 选项，GMM 式工具变量为 L(2/.).n，具体如下：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984, twostep  lags(2)
```




　　使用 `maxldep()` 选项，GMM 式工具变量为 L(2/6).n，具体如下：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta, clear  // 部分版本的 Stata 可能无法执行
xtabond n L(0/1).w L(0/2).(k ys) yr1980-yr1984, twostep lags(2) maxldep(5)
```


　　使用其他动态面板回归命令的方法：

- `xtdpd` 命令：使用 `dgmmiv(n, lagrange(2 5))`，将被解释变量的 2-5 阶滞后项作为 的工具变量；   
- `xtabond2` 命令：使用 `gmm(l.n, laglimits(2 5) collapse))`，`laglimits()` 限制滞后项的阶数，`collapse` 系统自动删减工具变量；   
- `xtdpdsys` 命令：使用 `maxldep(5)`，表示最多使用被解释变量的 5 阶滞后作为工具变量。   



###  大T小N型面板数据

　　上面介绍的 FD-GMM 和 SYS-GMM 适用于 大 N 小 T 的短面板数据，当研究样本为长面板数据 (大 T 小 N) 时，比如省级面板数据，GMM 估计可能不是最有效的。根据 Bruno(2005) 的做法，基于 Bootstrap 偏差纠正的 LSDV 估计可以在一定程度上克服 N 较小的问题。

　　下面，将通过一个模拟例子，来对 FD-GMM、SYS-GMM 和 bias corrected LSDV 的估计效果进行比较。

　　**数据生成过程 (DPG)**。该面板数据包含 10 个个体的 60 期数据，即$N=10$，$T=60$，变量具体构造如下：  
　　
$$
\begin{array}{c}
y_{i t}=0.9 y_{i t-1}+0.8 x_{i, t}+u_{i}+u_{t}+e_{i t-1} \\
\cot \alpha\left(x_{i t}, u_{i}\right) \neq 0 \\
x_{i t}=0.2 x_{i t-1}+v_{i t}
\end{array}  \tag{70}
$$

　　对应 Stata 命令：
```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
clear all
*help xtarsim //  xtarsim 是模拟生成面板数据的命令
xtarsim y x eta, n(10) t(60) gamma(0.9) beta(0.8) rho(0.2) one(corr 1) sn(9) seed(1234)

*模型估计

*用 xtabond 和 xtdpdsys 命令进行 FD-GMM 和 SYS-GMM 估计：

xtabond y x
est store FdGMM
xtdpdsys y x
est store SysGMM

*用 xtlsdvc 命令进行 bias corrected LSDV 估计：
*help xtlsdvc // 外部命令，需要下载安装词命令
xtlsdvc y x, initial(ab)  vcov(50)  // vcov(50) 计算标准误、显著性，需要较长等待时间
*initial(ab) 表示选择 Arellano 和 Bond (1991) 提出的 FD-GMM 估计为偏差纠正的初始量
est store LSDVab
xtlsdvc y x, initial(bb)  vcov(50)  // vcov(50) 计算标准误、显著性，需要较长等待时间
*initial(ab) 表示选择 Blundell 和 Bond (1998) 提出的 Sys-GMM 估计为偏差纠正的初始量
est store LSDVbb

local mm "FdGMM SysGMM LSDVab LSDVbb"
esttab `mm', mtitle(`mm') compress star(* 0.1 ** 0.05 *** 0.01)
```




　　把数据模拟中的$y_{i t-1}$的系数由0.9变为0.4，重复上述过程，再对估计结果进行比较。

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
clear all
xtarsim y x eta, n(10) t(60) gamma(0.4) beta(0.8) rho(0.2) one(corr 1) sn(9) seed(1234)
xtabond y x
est store FdGMM
xtdpdsys y x
est store SysGMM
xtlsdvc y x, initial(ab)  vcov(50)  
est store LSDVab
xtlsdvc y x, initial(bb)  vcov(50)
est store LSDVbb
local mm "FdGMM SysGMM LSDVab LSDVbb"
esttab `mm', mtitle(`mm') compress star(* 0.1 ** 0.05 *** 0.01)
```

　　可以看出，当$y_{i t-1}$的系数为 0.4， `XTLSDVC` 的优势非常有限；而当$y_{i t-1}$的系数为 0.9 时，`XTLSDVC` 的优势比较明显。
　　
## xtdpdgmm：动态面板数据模型一网打尽   

### 简介

　　对于动态面板数据模型 (Dynamic Panel Data, DPD)，直接用最小二乘法估计是有偏的，为解决这一问题，Arellano 和 Bond (1991)、 Arellano 和 Bover (1995)、以及 Blundell 和 Bond (1998) 等提出了「一阶差分 GMM (FD-GMM)」和「系统 GMM (SYS-GMM)」估计法。

　　相应地，Stata 也提供了 `xtabond`、`xtdpdsys`、以及 `xtabond2` 等早期估计 GMM 的命令。Kripfganz (2019) 在此基础上，编写了 `xtdpdgmm` 命令，该命令解决了 `xtabond2` 等命令的一些缺陷，并使估计更加灵活。特别的，该命令整合了 Ahn 和 Schmidt (1995) 非线性矩条件、更好解决了高度自相关问题、以及提供了 Hansen 等 (1996) 的迭代 GMM 估计。

　　本文的主要目的是介绍动态面板数据模型的两种估计方法，以及 `xtdpdgmm` 命令的应用。


### 估计方法

####  差分 GMM

　　考虑以下动态面板模型：   
　　
$$
y_{i t}=\alpha+\rho y_{i, t-1}+\boldsymbol{x}_{i i}^{\prime} \boldsymbol{\beta}+z_{i}^{\prime} \boldsymbol{\delta}+u_{i}+\varepsilon_{i t} \quad(t=2, \cdots, T)  \tag{71}
$$

　　通过一阶差分消去个体效应$u_{i}$，可得：

$$
\Delta y_{i t}=\rho \Delta y_{i, t-1}+\Delta x_{i t}^{\prime} \beta+\Delta \varepsilon_{i t} \quad(t=2, \cdots, T)  \tag{72}
$$

　　然而，由于$y_{i, t-1}$与$\varepsilon_{i t}$相关， 使得$\Delta y_{i, t-1} \equiv y_{i, t-1}-y_{i, t-2}$与$\Delta \varepsilon_{i, t} \equiv \varepsilon_{i, t-1}-\varepsilon_{i, t-2}$相关。也因此， 为内生变量，我们需要为其找到适当的工具变量才能得到一致估计。

　　为此，Anderson 和 Hsiao (1981) 认为由于$y_{i, t-2}$与$\Delta y_{i, t-1} \equiv y_{i, t-1}-y_{i, t-2}$相关，若$\varepsilon_{i}$不存在自相关，则$y_{i, t-2}$与$\Delta \varepsilon_{i, t} \equiv \varepsilon_{i, t}-\varepsilon_{i, t-1}$不相关，故$y_{i, t-2}$是$\Delta y_{i, t-1}$ 的有效工具变量。根据这一思想，更高阶的滞后变量${y_{i, t-3},y_{i, t-4},...}$ 也是有效工具变量，但是Anderson 和 Hsiao (1981) 估计并未加以利用，所以估计并非最有效。

　　Arellano 和 Bond (1991) 使用所有可能的滞后变量作为工具变量 (工具变量个数可能多于内生变量) 进行估计，这一方法又被称为「差分 GMM」。值得注意的是，在使用差分 GMM 时，扰动项$\varepsilon_{i}$不存在自相关，即 $Cov(\varepsilon_{it},\varepsilon_{is})=0$。

**差分 GMM 注意事项：**

- 如果$x_{it}$非严格外生，即虽然$x_{it}$与当期$\varepsilon_{it}$不相关，但与 $\varepsilon_{it-1}$相关，则$\Delta x_{i, t} \equiv x_{i, t}-x_{i, t-1}$与 $\Delta \varepsilon_{i, t} \equiv \varepsilon_{i, t}-\varepsilon_{i, t-1}$相关，使得$\Delta x_{i, t}$为内生变量。此时，可以使用${x_{i, t-1},x_{i, t-2},...}$作为$\Delta x_{i, t}$的工具变量。  

- 如果T很大，则会有很多工具变量，进而容易产生弱工具变量问题。同时，也会弱化 Hansen 统计量，甚至出现p值等于1的不可信结果。解决方法一是在使用 `xtabond` 命令时，限制最多使用q阶滞后变量作为工具变量。方法二是使用折叠的 Ⅳ 式工具变量，而不使用展开的 GMM 式工具变量。  

- 不随时间变化的变量$z_{i}$被消掉了，故差分 GMM 无法估计$z_{i}$的系数。  

- 如果序列$y_{i}$具有很强的持续性，即一阶自回归系数接近于1，则$y_{i, t-2}$与$\Delta y_{i, t-1} \equiv y_{i, t-1}-y_{i, t-2}$ 的相关性可能很弱，进而导致弱工具变量问题。

#### 水平 GMM

　　为克服上述差分 GMM 将不随时间变化的变量$z_{i}$消掉、以及序列具有很强的持续性等问题，Arellano 和 Bover(1995)重新回到了差分之前的水平方程，并使用${\Delta{y_{i, t-1},\Delta y_{i, t-2},...}}$作为$y_{i, t-1}$的工具变量。但前提是需假设$\varepsilon_{i}$ 不存在自相关，以及${\Delta{y_{i, t-1},\Delta y_{i, t-2},...}}$与个体效应$u_{i}$不相关。上述过程也被称为「水平 GMM」。

#### 系统 GMM

　　Blundell 和 Bond (1998) 将差分 GMM 与水平 GMM 联合进行 GMM 估计，即「系统 GMM」。与差分 GMM 相比，系统 GMM的优点是，可以提高估计的效率，并且可以估计不随时间变化的变量 的系数。其缺点是，必须假定以及${\Delta{y_{i, t-1},\Delta y_{i, t-2},...}}$与个体效应$u_{i}$无关。

### xtdpdgmm 命令介绍

#### xtdpdgmm 命令语法

`xtdpdgmm` 命令的安装：

```
ssc install xtdpdgmm, replace  
```

`xtdpdgmm` 命令的语法：

```
 xtdpdgmm depvar [indepvars] [if] [in] [, options]
```

　　其中，`option` 具体选项如下：

- `iv(iv_spec)`：指定标准式工具变量，并可指定任意多次；
- `gmmiv(gmmiv_spec)`：指定 GMM 式工具变量，并可指定任意多次；
- `nl (nl_spec)`：添加由误差协方差结构得出的非线性矩条件；
- `collapse`：折叠式工具变量为标准式工具变量；
- `model(model_spec)`：设置工具变量的默认形式及标准误；
- `norescale`：不重新缩放转换后的矩条件；
- `wmatrix(wmat_spec)`：指定用于获得一阶 GMM 估计或两步 GMM 　　估计的初始估计的加权矩阵；
- `onestep|twostep`：确定一步估计或两步估计；
- `igmm`：使用迭代 GMM 估计;
- `teffects`：模型增加时间效应；
- `overid`：计算简化模型的过度识别统计信息；
- `noconstant`：无常数项；
- `vce(vce_spec)`：设置聚类标准误的估计方式进行稳健标准误估计；
- `auxiliary`：显示所有系数作为辅助参数；
- `level(#)`：设置置信区间，默认为水平为 95%；
- `small`：进行自由度调整并报告小样本统计数据；
- `coeflegend`：显示图例而不是统计信息；
- `noheader`：不显示输出表头；
- `notable`：不显示输出系数表；
- `nofootnote`：不显示系数表下脚注；
- `display_options`：控制列和列的格式，行间距，行宽，需要省略的变量以及基础空白单元格、因子变量的标记；
- `noanalytic`：不使用解析封闭解。
- `from(init_spec)`：确定系数的初始值；
- `nodots`：在迭代 GMM 估计中的每个步骤中显示迭代日志，而不是点；
- `igmm_options`：控制迭代的 GMM 过程；
- `minimize_options`：控制最小化过程。

#### xtdpdgmm 命令实操

　　以 abdata.dta 数据集为例，该数据集是 140 个国家 1976 年到 1984 年的各种宏观指标的面板数据。**id** 代表每个国家的标号，**year** 代表年份，其他变量包括就业率 **emp**、平均工资 **wage**、投资占 GDP 的百分比 **cap** 等。  

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
describe          //数据结构
sum               //描述性统计
xtset id year     //声明面板数据

```

#### 一阶差分 GMM 估计：  

　　差分 GMM 一步估计：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, model(diff) gmm(n, lag(2 .)) gmm(w, lag(1 .)) gmm(k, lag(. .)) nocons 
```


　　差分 GMM 两步估计：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, model(diff) gmm(n, lag(2 .)) gmm(w, lag(1 .)) gmm(k, lag(. .)) nocons two vce(r) 
*序列相关检验
estat serial
*过度识别检验
estat overid
```





### 差分 GMM 与系统 GMM 对比  


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
*差分 GMM
xtdpdgmm L(0/1).n w k, model(diff) collapse gmm(n, lag(2 4)) gmm(w, lag(1 3))  gmm(k, lag(0 2)) nocons two vce(r)
estat serial, ar(1/3)
estat overid

*系统 GMM
xtdpdgmm L(0/1).n w k, model(diff) collapse gmm(n, lag(2 4)) gmm(w k, lag(1 3))  gmm(n, lag(1 1) diff model(level)) gmm(w k, lag(0 0) diff model(level)) two vce(r)
estat serial, ar(1/3)
estat overid
```


#### 各估计方式呈现

　　具有严格外生变量的 Anderson-Hsiao IV 估计：  


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, iv(L2.n w k, d) m(d) nocons
xtdpdgmm L(0/1).n w k, iv(L2.n) iv(w k, d) m(d) nocons
```



　　具有严格外生变量和工具变量约束的 Arellano-Bond 一步 GMM 估计：   



```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, gmm(L.n, l(1 4) c) iv(w k, d) m(d) nocons
```


　　具有前定变量和工具变量约束的 Arellano-Bover 两步 GMM 估计：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, gmm(L.n w k, l(0 3) c) m(fod) two vce(r)
```
　　具有前定变量和工具变量约束的 Ahn-Schmidt 两步 GMM 估计：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, gmm(L.n w k, l(1 4) c) m(d) nl(noser) two vce(r)
xtdpdgmm L(0/1).n w k, gmm(L.n w k, l(1 4) c) m(d) nl(iid) two vce(r)
```
　　具有前定变量和工具变量约束的 Blundell-Bond 两步 GMM 估计:

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, gmm(L.n w k, l(1 4) c m(d)) iv(L.n w k, d) two vce(r)
```

　　具有前定变量的 Hayakawa-Qi-Breitung IV 估计量：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm L(0/1).n w k, iv(L.n w k, bod) m(fod) nocons
```

　　复制静态 (加权) 固定效应估计：


```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm n w k, iv(w k) m(md)
by id: egen weight = count(e(sample))
replace weight = sqrt(weight/(weight-1))
xtreg n w k [aw=weight], fe
```


　　复制静态 (未加权) 固定效应估计：

```{stata engine.path = "D:/soft/stata/StataMP-64.exe"}
sysdir set PLUS "D:\soft\stata\ado\plus"
use E:\Mirror\StataLearn\StataData\abdata.dta     //调用网络数据
xtset id year     //声明面板数据
xtdpdgmm n w k, iv(w k) m(md) nores
xtreg n w k, fe
```


</font>

